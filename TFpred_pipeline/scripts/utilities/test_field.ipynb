{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os, sys, json\n",
    "from datetime import date\n",
    "import parsl\n",
    "from parsl.app.app import python_app\n",
    "import subprocess\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " '/lus/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan/TFpred_pipeline/test_run')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whereis_script = '/lus/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan/TFpred_pipeline/test_run/' #os.path.dirname(sys.argv[0]) # or os.path.dirname(__file__)\n",
    "os.chdir(whereis_script), os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mtdata = '../metadata/aggregation_config_freedman_FOXA1.json'\n",
    "\n",
    "agg_type = 'aggByMean'\n",
    "\n",
    "script_path = '../scripts'\n",
    "utils_path = os.path.join(script_path, 'utilities')\n",
    "sys.path.append(utils_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{mtdata}') as f:\n",
    "    parameters = json.load(f)\n",
    "\n",
    "    enformer_predictions_path = parameters['enformer_prediction_path']\n",
    "    log_file = parameters['log_file']\n",
    "    dataset_type = parameters['dataset_type']# e.g. \"kawakami\" or \"cistrome\"\n",
    "    todays_date = parameters['run_date']\n",
    "    base_path = parameters['predictions_folder']\n",
    "    TF = parameters['transcription_factor']\n",
    "    individuals = parameters['individuals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Currently on freedman\n"
     ]
    }
   ],
   "source": [
    "print(f'[INFO] Currently on {dataset_type}')\n",
    "\n",
    "save_dir = f'{base_path}/aggregated_predictions/{dataset_type}_{TF}_{todays_date}'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "if individuals is None:\n",
    "    ids_names = [dataset_type]\n",
    "elif isinstance(individuals, list):\n",
    "    ids_names = individuals\n",
    "\n",
    "log_data_all = pd.read_csv(log_file)\n",
    "\n",
    "# use parsl if the num of rows of log_data is more than 10000\n",
    "use_parsl = False\n",
    "\n",
    "predict_utils_one = f'{script_path}/utilities/utility_functions.py'\n",
    "exec(open(predict_utils_one).read(), globals(), globals())\n",
    "\n",
    "if use_parsl == True:\n",
    "    #bpath = os.path.join(base_path, 'modeling_pipeline')\n",
    "    print(f'[INFO] Using parsl. Aggregation will be split into multiple files, and batches will be collected into one later.')\n",
    "    parsl_params = {'working_dir':base_path, 'job_name':'aggregate_predictions', 'queue':\"preemptable\", 'walltime':\"05:59:00\", 'num_of_full_nodes':1, 'min_num_blocks':0, 'max_num_blocks':10}\n",
    "    parsl.load(parslConfiguration.localParslConfig_htpool(parsl_params))\n",
    "\n",
    "collection_fxn = return_prediction_function(use_parsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motif</th>\n",
       "      <th>individual</th>\n",
       "      <th>status</th>\n",
       "      <th>sequence_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr12_92688598_92688607</td>\n",
       "      <td>LuCaP_136</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hr9_122819978_122819987</td>\n",
       "      <td>LuCaP_136</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr9_18363310_18363319</td>\n",
       "      <td>LuCaP_136</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr5_160240472_160240481</td>\n",
       "      <td>LuCaP_136</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr20_11244716_11244725</td>\n",
       "      <td>LuCaP_136</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9099</th>\n",
       "      <td>chrX_68854754_68854763</td>\n",
       "      <td>LuCaP_141</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9100</th>\n",
       "      <td>chr9_122819978_122819987</td>\n",
       "      <td>LuCaP_141</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9101</th>\n",
       "      <td>chr7_3576376_3576385</td>\n",
       "      <td>LuCaP_141</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9174</th>\n",
       "      <td>chr1_176593308_176593317</td>\n",
       "      <td>LuCaP_141</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9181</th>\n",
       "      <td>chr5_153476501_153476510</td>\n",
       "      <td>LuCaP_141</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9103 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         motif individual     status sequence_type\n",
       "0      chr12_92688598_92688607  LuCaP_136  completed           var\n",
       "1      hr9_122819978_122819987  LuCaP_136  completed           var\n",
       "2       chr9_18363310_18363319  LuCaP_136  completed           var\n",
       "3     chr5_160240472_160240481  LuCaP_136  completed           var\n",
       "4      chr20_11244716_11244725  LuCaP_136  completed           var\n",
       "...                        ...        ...        ...           ...\n",
       "9099    chrX_68854754_68854763  LuCaP_141  completed           var\n",
       "9100  chr9_122819978_122819987  LuCaP_141  completed           var\n",
       "9101      chr7_3576376_3576385  LuCaP_141  completed           var\n",
       "9174  chr1_176593308_176593317  LuCaP_141  completed           var\n",
       "9181  chr5_153476501_153476510  LuCaP_141  completed           var\n",
       "\n",
       "[9103 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data_all = pd.read_csv(log_file)\n",
    "log_data_all.drop_duplicates(subset=['motif'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9103, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          motif individual     status sequence_type\n",
      "9098    chr12_92688598_92688607  LuCaP_141  completed           var\n",
      "9099     chrX_68854754_68854763  LuCaP_141  completed           var\n",
      "9100   chr9_122819978_122819987  LuCaP_141  completed           var\n",
      "9101       chr7_3576376_3576385  LuCaP_141  completed           var\n",
      "9102     chr3_24951897_24951906  LuCaP_141  completed           var\n",
      "...                         ...        ...        ...           ...\n",
      "18195   chr12_23533600_23533609  LuCaP_141  completed           var\n",
      "18196  chr5_102611585_102611594  LuCaP_141  completed           var\n",
      "18197    chr8_84108965_84108974  LuCaP_141  completed           var\n",
      "18198   chr21_24828757_24828766  LuCaP_141  completed           var\n",
      "18199    chr4_79041264_79041273  LuCaP_141  completed           var\n",
      "\n",
      "[9102 rows x 4 columns]\n",
      "(9102, 4)\n",
      "[range(1138, 2276), range(2276, 3414), range(3414, 4552), range(4552, 5690), range(5690, 6828), range(6828, 7966), range(7966, 9102)]\n",
      "['0: 1138']\n"
     ]
    }
   ],
   "source": [
    "ids_names = ['LuCaP_141']\n",
    "\n",
    "for each_id in ids_names:\n",
    "    log_data = log_data_all.loc[log_data_all['individual'] == each_id, ]\n",
    "    log_data = log_data.drop_duplicates(subset=['motif']) #.iloc[1:1000, ]\n",
    "\n",
    "    print(log_data)\n",
    "\n",
    "    print(log_data.shape)\n",
    "\n",
    "    range_batches = generate_batch(range(0, log_data.shape[0]), batch_n=8)\n",
    "\n",
    "    ind_path = os.path.join(enformer_predictions_path, each_id)\n",
    "\n",
    "    app_futures = []\n",
    "    for i, range_batch in enumerate(range_batches):\n",
    "\n",
    "        print(list(range_batches))\n",
    "        app_futures.append(f'{i}: {len(range_batch)}')\n",
    "\n",
    "        # print(i)\n",
    "        # app_futures.append(collection_fxn(each_id=each_id, log_data=log_data.iloc[range_batch, ], predictions_path=ind_path, TF=TF, agg_types=[agg_type], base_path=base_path, save_dir=save_dir, batch_num=i))\n",
    "\n",
    "    print(app_futures)\n",
    "\n",
    "    if use_parsl == True:\n",
    "        app_execs = [r.result() for r in app_futures]\n",
    "\n",
    "    # cmd = f\"for i in `ls {save_dir}/{each_id}_{agg_type}_{TF}_batch_*.csv.gz`; do zcat $i | sed '1d'; done | pigz -c >{save_dir}/{each_id}_{agg_type}_{TF}.csv.gz\"    \n",
    "    # p = subprocess.Popen(cmd, shell=True)\n",
    "    # print(f'[INFO] Status: Aggregation complete for {log_data.shape[0]} predictions for {each_id}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6dcac1a71ccad94eb769456e80f90aa894f3068a5275ffeae8fac07a2d93c97a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
