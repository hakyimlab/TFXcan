---
title: "TF binding analysis 2 | Model comparisons"
author: "Temi"
format: 
  pdf: 
    toc: true
    number-sections: true
    code-line-numbers: true
---

```{r}
knitr::opts_chunk$set(fig.width=12, fig.height=8, cache=F)
```

```{r, results='hide', message=FALSE, warning=FALSE}
rm(list=ls())

setwd('/projects/covid-ct/imlab/users/temi/projects/TFXcan/scripts/')

library(glue)
library(R.utils)
library(data.table)
library(glmnet)
library(doMC)
library(ROCR)
library(Matrix)
library(reshape2)
library(tidyverse)
library(foreach)
library(doParallel)
library(tidymodels)
library(broom)
```

```{r}
plots_dir <- '../plots'
models_dir <- '../models'
```

```{r}
TF <- 'GATA3'
cistrome_dir <- '/projects/covid-ct/imlab/data/cistrome/compressed'
hf_info <- data.table::fread(glue('{cistrome_dir}/human_factor_full_QC.txt'))
TF_DCID <- hf_info[hf_info$Factor == TF, ]
head(TF_DCID)
```

https://stats.stackexchange.com/questions/138569/why-is-lambda-within-one-standard-error-from-the-minimum-is-a-recommended-valu

\newpage

For plotting, I need to load in the enformer annotations
```{r}
enformer_annotations <- data.table::fread('../info-files/enformer_tracks_annotated-resaved.txt')
enformer_annotations <- enformer_annotations[!is.na(enformer_annotations$assay), ]
```

```{r}
# using an individual for now >> will do this across all 3 individuals later
ind <- 'HG00479'
```

There are 5 major categories
```{r}
assays <- enformer_annotations$assay |> unique()
assays
```

```{r}
z_list <- list()
for(i in 1:length(assays)){
    z <- combn(assays, i)
    z_list[[i]] <- t(z) |> as.data.frame()
}

assays_dt <- plyr::rbind.fill(z_list)
```


### helper functions

```{r}
collate_coefficients <- function(fit){
    min_error_index <- fit$index['min', ]
    one_sd_index <- fit$index['1se', ]

    dimensions <- fit$glmnet.fit$beta@Dim
    coef_mat <- as.data.frame(summary(fit$glmnet.fit$beta))

    temp_mat <- matrix(data=NA, nrow=dimensions[1], ncol=dimensions[2])
    #print(dim(temp_mat))
    for(i in 1:nrow(coef_mat)){
        temp_mat[coef_mat[i, 'i'], coef_mat[i, 'j']] <- coef_mat[i, 'x']
    }

    temp_mat[is.na(temp_mat)] <- 0

    fit_beta <- cbind(temp_mat[, min_error_index], temp_mat[, one_sd_index])
    # what features were used?
    feature_data <- enformer_annotations[enformer_annotations$feature_names %in% (fit$glmnet.fit$beta |> rownames()), c('assay', 'feature_names')]

    fit_beta <- as.data.frame(cbind(fit_beta, feature_data))

    return(fit_beta)
}

test_models <- function(model, X_test_set, y_test_set){

    features <- model$glmnet.fit$beta |> rownames()
    X_test_set <- X_test_set[, features]
    assess.glmnet(model, newx = X_test_set, newy = y_test_set) |> unlist()
}
```

## Load the models

```{r}
aggModels_names <- c('aggByCenter', 'aggByMean', 'aggByMeanUpstream', 'aggByMeanDownstream', 'aggByMeanUpstreamDownstream')

aggModels <- lapply(aggModels_names, function(each_agg){
    readRDS(glue('{models_dir}/enet_models_{each_agg}.RData'))
})

names(aggModels) <- aggModels_names
```

I need to curate predictions across the models (without a test set yet)

```{r}
cv_metrics <- function(fit, lambda = 'lambda.1se'){
    whlm <- which(fit$lambda == fit[[lambda]])
    # mse
    mse <- fit$cvm[whlm]
    out <- with(fit$glmnet.fit,
        {
            tLL <- nulldev - nulldev * (1 - dev.ratio)[whlm]
            k <- df[whlm]
            n <- nobs
            list('AICc' = - tLL + 2 * k + 2 * k * (k + 1) / (n - k - 1),
                        'BIC' = log(n) * k - tLL)
        })

    out$mse <- mse
    return(do.call(cbind, out) |> as.data.frame())
}

```

```{r}
aggModels$aggByCenter[[1]] |> cv_metrics()
```

```{r}
aggModels_metrics <- lapply(aggModels, function(each_model_list){
    out <- do.call(rbind, lapply(each_model_list, cv_metrics))
})
names(aggModels_metrics) <- aggModels_names
```

### predict on the test set
```{r}
aggModels_predict_test <- lapply(seq_along(aggModels), function(i){
    test_data <- read.csv(glue('/projects/covid-ct/imlab/users/temi/projects/TFXcan/output/train-test-data/test_{names(aggModels[i])}_{ind}.csv'))

    X_test <- as.matrix(test_data[, -c(1)])
    y_test <- as.matrix(test_data[, 1])

    do.call(rbind, lapply(aggModels[[i]], test_models, X_test, y_test)) |> as.data.frame()
})

```

```{r}
# select the models with the minimum mse
best_features <- lapply(seq_along(aggModels_predict_test), function(i){
    whmin <- which.min(aggModels_predict_test[[i]][, 4])

    feats <- assays_dt[whmin, ]
    feats <- feats[!is.na(feats)]

    paste(feats, collapse=' + ')
})

best_models <- lapply(seq_along(aggModels_predict_test), function(i){
    whmin <- which.min(aggModels_predict_test[[i]][, 4])
    aggModels[[i]][[whmin]]
})

names(best_features) <- aggModels_names
names(best_models) <- aggModels_names
```

```{r}

aggMethods <- do.call(c, 
    lapply(seq_along(best_features), function(mi){
        glue('{names(best_features)[mi]}: {best_features[[mi]]}')
    })
)

best_metrics <- lapply(seq_along(aggModels_predict_test), function(i){
    whmin <- which.min(aggModels_predict_test[[i]][, 4])
    aggModels_predict_test[[i]][whmin, ]
})

best_metrics <- do.call(rbind, best_metrics) |> as.data.frame()
best_metrics <- data.frame(method=aggMethods, best_metrics)
best_metrics

```


```{r}
df_beta_list <- lapply(best_models, collate_coefficients)
```

```{r}
useColors <- RColorBrewer::brewer.pal(n=8, name='Dark2')
df_beta_labels <- c('For lambda with minimum mean cv error', 'For largest lambda with 1 s.e within the mininum error')
```

```{r}
# layout(matrix(c(1, 2, 3, 4, 5), nrow=5, ncol=1, byrow=T), height=c(6, 6, 6, 6, 6))
# layout.show(5)

for(mi in seq_along(df_beta_list)){
    bmodel_df_beta <- df_beta_list[[mi]]
    bmodel_df_beta_split <- split(bmodel_df_beta, bmodel_df_beta$assay)

    # define the layout
    layout(matrix(c(1,3,2,3), nrow = 2, ncol = 2, byrow = T), height=c(5, 5), width=c(8,2))
    par(mar=c(0.5,2.5,2,2) + 0.1, oma=c(3.5, 2.0, 3.5, 0.5) + 0.1)

    for(i in 1:2){
        ylimits <- c(min(bmodel_df_beta[, i]), max(bmodel_df_beta[, i]))
        #print(ylimits)

        plot(x=bmodel_df_beta_split[[1]] |> row.names() |> as.numeric(), y=bmodel_df_beta_split[[1]][, i], type='l', col=useColors[1], xlim=c(1, nrow(bmodel_df_beta)), ylim=ylimits, xaxt='n', main=df_beta_labels[i])

        for(j in 2:length(bmodel_df_beta_split)){
            lines(x=bmodel_df_beta_split[[j]] |> row.names() |> as.numeric(), y=bmodel_df_beta_split[[j]][, i], col=useColors[j])
        }
    #mtext('TTTT', side=1, outer=T, cex=1.2)
    }

    axis(1, at=seq(1, nrow(bmodel_df_beta)))
    mtext('tracks', side=1, outer=T, cex=1.2, line=2, adj=0.4)
    mtext('coefficients', side=2, outer=T, cex=1.2)
    mtext(glue('{names(best_features)[mi]}: {best_features[[mi]]}'), side=3, outer=T, cex=1.3, adj=0)

    par(mai=c(0,0,0,0))
    plot.new()
    legend('right', legend=names(bmodel_df_beta_split), col=useColors[1:length(bmodel_df_beta_split)], lty=1, bty='n')
}
```

What about models where I remove the TFs?

```{r}
assays_dt[
apply(assays_dt, 1, function(each_row){
    !'TF ChIP-seq' %in% each_row
}), ]
```


$y_{i} \sim \sum_{i=1}^{m}\sum_{j=1}^{k}x_{ij}\beta_{ij} + \epsilon$


$log(\frac{p_{i}}{(1-p_{i})}) = \beta_{0} + \sum_{i=1}^{m}\sum_{j=1}^{k}x_{ij}\beta_{ij}$


$p_{i} = \frac{1}{1-e^{-x_{i}}} = \frac{1}{1-e^{-(\beta_{0} + \sum_{i=1}^{m}\sum_{j=1}^{k}x_{ij}\beta_{ij})}}$

where $m$ is the number of predictors, in this case the number of tracks or thereabouts from ENFORMER, $k$ is the number of categories, in this case any of the following:

1. ATAC-seq
2. TF ChIP-seq
3. Histone ChIP-seq
4. CAGE experiments
5. DNase-seq,

$y$ is the presence or absence of TF-binding, in this case GATA3 binding, $x_{ij}$ is the predictor (from ENFORMER) of sample $i$ belonging to category $j$ and aggregated by any of the following:

1. mean of the 8 bins upstream and downstream the motif bin
2. just the motif bin
3. mean of all the bins
4. mean of only the upstream bins
5. mean of only the downstream bins. 





```{r}

```

