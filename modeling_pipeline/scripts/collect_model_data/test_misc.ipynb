{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Currently on kawakami\n"
     ]
    }
   ],
   "source": [
    "each_id = \"kawakami\"\n",
    "\n",
    "print(f'[INFO] Currently on {each_id}')\n",
    "\n",
    "upstream = list(range(0, 8))\n",
    "center = [8]\n",
    "downstream = list(range(9, 17))\n",
    "\n",
    "base_path = '/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan'\n",
    "enformer_predictions_path = f'{base_path}/enformer_pipeline/enformer_predictions/{each_id}_reference/{each_id}_FOXA1'\n",
    "log_path = f'{base_path}/enformer_pipeline/predictions-log'\n",
    "\n",
    "save_dir = f'{base_path}/modeling_pipeline/data/train-test-val/{each_id}'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "TF = 'FOXA1'\n",
    "data_names = ['aggByCenter']\n",
    "#data_names = ['aggByMean', 'aggByCenter', 'aggByUpstream', 'aggByDownstream', 'aggByUpstreamDownstream']\n",
    "\n",
    "logpath = f'{log_path}/{each_id}_{TF}_predictions_log.csv'\n",
    "log_data = pd.read_csv(logpath)\n",
    "log_data = log_data.drop_duplicates(subset=['motif'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motif</th>\n",
       "      <th>individual</th>\n",
       "      <th>status</th>\n",
       "      <th>sequence_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr7_95926609_95926618</td>\n",
       "      <td>kawakami_FOXA1</td>\n",
       "      <td>completed</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr20_44482016_44482025</td>\n",
       "      <td>kawakami_FOXA1</td>\n",
       "      <td>completed</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr6_154796142_154796151</td>\n",
       "      <td>kawakami_FOXA1</td>\n",
       "      <td>completed</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr21_34635998_34636007</td>\n",
       "      <td>kawakami_FOXA1</td>\n",
       "      <td>completed</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr5_52311206_52311215</td>\n",
       "      <td>kawakami_FOXA1</td>\n",
       "      <td>completed</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82036</th>\n",
       "      <td>chr5_142562333_142562342</td>\n",
       "      <td>kawakami_FOXA1</td>\n",
       "      <td>completed</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82037</th>\n",
       "      <td>chr5_19894347_19894356</td>\n",
       "      <td>kawakami_FOXA1</td>\n",
       "      <td>completed</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82042</th>\n",
       "      <td>chr20_57677519_57677528</td>\n",
       "      <td>kawakami_FOXA1</td>\n",
       "      <td>completed</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82047</th>\n",
       "      <td>chr4_90773272_90773281</td>\n",
       "      <td>kawakami_FOXA1</td>\n",
       "      <td>completed</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82048</th>\n",
       "      <td>chr12_14680762_14680771</td>\n",
       "      <td>kawakami_FOXA1</td>\n",
       "      <td>completed</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39967 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          motif      individual     status sequence_type\n",
       "0        chr7_95926609_95926618  kawakami_FOXA1  completed           ref\n",
       "1       chr20_44482016_44482025  kawakami_FOXA1  completed           ref\n",
       "2      chr6_154796142_154796151  kawakami_FOXA1  completed           ref\n",
       "3       chr21_34635998_34636007  kawakami_FOXA1  completed           ref\n",
       "4        chr5_52311206_52311215  kawakami_FOXA1  completed           ref\n",
       "...                         ...             ...        ...           ...\n",
       "82036  chr5_142562333_142562342  kawakami_FOXA1  completed           ref\n",
       "82037    chr5_19894347_19894356  kawakami_FOXA1  completed           ref\n",
       "82042   chr20_57677519_57677528  kawakami_FOXA1  completed           ref\n",
       "82047    chr4_90773272_90773281  kawakami_FOXA1  completed           ref\n",
       "82048   chr12_14680762_14680771  kawakami_FOXA1  completed           ref\n",
       "\n",
       "[39967 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_modeling_data_for_kawakami(each_id, log_data, predictions_path, TF, data_names, base_path, save_dir):\n",
    "\n",
    "    import h5py\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import tqdm\n",
    "    # read in one of the files\n",
    "\n",
    "    exec(open(f'{base_path}/modeling_pipeline/scripts/collect_model_data/utility-functions.py').read(), globals(), globals())\n",
    "\n",
    "    kawakami_predictions = {}\n",
    "\n",
    "    for dt in log_data.loc[log_data['sequence_type'] == 'ref', ].motif.values.tolist():\n",
    "        fle = f'{predictions_path}/{dt}_predictions.h5'\n",
    "        print(fle)\n",
    "        if os.path.isfile(fle):\n",
    "            with h5py.File(fle, 'r') as f:\n",
    "                filekey = list(f.keys())[0]\n",
    "                # should I select tracks? ; maybe not yet\n",
    "                kawakami_predictions[dt] = np.vstack(list(f[filekey]))\n",
    "        else:\n",
    "            print('File does not exist')\n",
    "\n",
    "    print(f'[INFO] Finished collecting {len(kawakami_predictions)} predictions for {each_id}')\n",
    "\n",
    "    dt_aggbycenter = agg_by_center(kawakami_predictions, center=8)\n",
    "    data_list = [dt_aggbycenter]\n",
    "\n",
    "    # test_aggbymean, test_aggbycenter, test_aggbymean_upstream, test_aggbymean_downstream, test_aggbymean_upstream_downstream = agg_byall(freedman_predictions)\n",
    "    # data_list = [test_aggbymean, test_aggbycenter, test_aggbymean_upstream, test_aggbymean_downstream, test_aggbymean_upstream_downstream]\n",
    "\n",
    "    for i, dt in enumerate(data_list):\n",
    "\n",
    "        ty = pd.concat([pd.Series(list(kawakami_predictions.keys())), pd.DataFrame(dt)], axis=1)\n",
    "\n",
    "        column_names = ['id', 'class']\n",
    "        column_names.extend([f'f_{i}' for i in range(1, ty.shape[1] - 1)])\n",
    "\n",
    "        ty = ty.set_axis(column_names, axis=1, copy=False)\n",
    "\n",
    "        ty.to_csv(path_or_buf=f'{save_dir}/{each_id}_{data_names[i]}_{TF}.csv.gz', index=False, compression='gzip')\n",
    "    print(f'[INFO] Finished saving data for {each_id}')\n",
    "\n",
    "    return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Finished collecting 0 predictions for kawakami\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m collected \u001b[39m=\u001b[39m collect_modeling_data_for_kawakami(each_id\u001b[39m=\u001b[39;49meach_id, log_data\u001b[39m=\u001b[39;49mlog_data, predictions_path\u001b[39m=\u001b[39;49menformer_predictions_path, TF\u001b[39m=\u001b[39;49mTF, data_names\u001b[39m=\u001b[39;49mdata_names, base_path\u001b[39m=\u001b[39;49mbase_path, save_dir\u001b[39m=\u001b[39;49msave_dir)\n\u001b[1;32m      3\u001b[0m \u001b[39m#print(collected)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[INFO] Status: \u001b[39m\u001b[39m{\u001b[39;00mcollected\u001b[39m}\u001b[39;00m\u001b[39m for \u001b[39m\u001b[39m{\u001b[39;00mlog_data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m predictions for \u001b[39m\u001b[39m{\u001b[39;00meach_id\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn [9], line 27\u001b[0m, in \u001b[0;36mcollect_modeling_data_for_kawakami\u001b[0;34m(each_id, log_data, predictions_path, TF, data_names, base_path, save_dir)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFile does not exist\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[INFO] Finished collecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(kawakami_predictions)\u001b[39m}\u001b[39;00m\u001b[39m predictions for \u001b[39m\u001b[39m{\u001b[39;00meach_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m dt_aggbycenter \u001b[39m=\u001b[39m agg_by_center(kawakami_predictions, center\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m)\n\u001b[1;32m     28\u001b[0m data_list \u001b[39m=\u001b[39m [dt_aggbycenter]\n\u001b[1;32m     30\u001b[0m \u001b[39m# test_aggbymean, test_aggbycenter, test_aggbymean_upstream, test_aggbymean_downstream, test_aggbymean_upstream_downstream = agg_byall(freedman_predictions)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m# data_list = [test_aggbymean, test_aggbycenter, test_aggbymean_upstream, test_aggbymean_downstream, test_aggbymean_upstream_downstream]\u001b[39;00m\n",
      "File \u001b[0;32m<string>:93\u001b[0m, in \u001b[0;36magg_by_center\u001b[0;34m(pred_tracks, center)\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl-tools/lib/python3.10/site-packages/numpy/core/shape_base.py:282\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    281\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "collected = collect_modeling_data_for_kawakami(each_id=each_id, log_data=log_data, predictions_path=enformer_predictions_path, TF=TF, data_names=data_names, base_path=base_path, save_dir=save_dir)\n",
    "\n",
    "#print(collected)\n",
    "\n",
    "print(f'[INFO] Status: {collected} for {log_data.shape[0]} predictions for {each_id}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('dl-tools')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6dcac1a71ccad94eb769456e80f90aa894f3068a5275ffeae8fac07a2d93c97a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
