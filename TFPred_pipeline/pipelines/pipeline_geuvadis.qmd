---
title: "Complete TFpred Pipeline - Using Geuvadis data/vcf files"
author: "Temi"
date: 'Wed Jan 25 2023'
format: 
  pdf: 
    toc: true
    number-sections: true
    code-line-numbers: true
---

```{r}
library(glue)
library(rjson)
library(data.table)
library(GenomicRanges)
library(parallel)
library(tidyverse)
library(jsonlite)
library(xlsx)
library(reticulate)
```
```{r}
<<<<<<< HEAD
imlab_dir <- '/lus/grand/projects/TFXcan/imlab'
=======
imlab_dir <- '/lus/grand/projects/covid-ct/imlab'
>>>>>>> 8d1e50b0eb3dd8bdfc1db9105ea1984253c9762d
data_dir <- glue('{imlab_dir}/data/freedman_data/peaks_liftover')
project_dir <- glue('{imlab_dir}/users/temi/projects/TFXcan/TFPred_pipeline')
homer_dir <- glue('/lus/grand/projects/covid-ct/imlab/users/temi/software/homer')
```

```{r}
dataset <- 'subset1KGgenomes'
TF <- 'AR'
todays_date <- data_date <- run_date <- "2023-02-17" #Sys.Date()
```

```{r}
peaks_dir <- glue('{project_dir}/files/peaks_files/{dataset}_{TF}')
if(!dir.exists(peaks_dir)){
    dir.create(peaks_dir, recursive=T)
} 

homer_files_dir <- glue('{project_dir}/files/homer_files/{dataset}_{TF}')
if(!dir.exists(homer_files_dir)){
    dir.create(homer_files_dir, recursive=T)
}

regions_dir <- glue('{project_dir}/files/defined_regions/{dataset}_{TF}')
if(!dir.exists(regions_dir)){
    dir.create(regions_dir, recursive=T)
}

common_dir <- glue('{project_dir}/files/homer_files/common_files')
if(!dir.exists(common_dir)){
    dir.create(common_dir, recursive=T)
}
```


```{r}
valid_chromosomes <- c(paste('chr', 1:22, sep=''), "chrX")
valid_chromosomes
```

```{r}
pat <- paste0('*.', valid_chromosomes, '.*vcf.gz$', collapse='|') # paste0('^', TF_info$DCid, collapse='_*|')
vcfs_dir <- glue('{imlab_dir}/data/GEUVADIS/vcf_snps_only')
grep(pattern=glue('{pat}'), list.files(vcfs_dir), value=TRUE)
```

```{r}
vcf_files <- lapply(valid_chromosomes, function(chr){
    pat <- paste0('*.\\b', chr, '\\b.*vcf.gz$', collapse='|')
    #print(pat)
    grep(pattern=glue('{pat}'), list.files(vcfs_dir), value=TRUE)
})
names(vcf_files) <- valid_chromosomes
vcf_files
```

```{r}
vcf_files <- list(folder=glue('{imlab_dir}/data/GEUVADIS/vcf_snps_only'), files=vcf_files)
vcf_files
```

```{r}
list.files(vcfs_dir, pattern=glue('*.{pat}.*vcf.gz'))
```

```{r}
predictor_file <- glue('/lus/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan/baca_cwas/predictors/baca_cwas_{TF}_regions_hg38_2023-01-27.csv')
predictor_file ; file.exists(predictor_file)
```
```{r}
metadata_dir <- glue('{project_dir}/config_files')
if(!dir.exists(metadata_dir)){
    dir.create(metadata_dir, recursive=T)
} else {
    print('Metadata folder exists')
}
```

```{r}
# check that your individuals are present in the vcf
individuals_1kg <- data.table::fread(glue('{project_dir}/metadata/samples_1KG_vcf.txt'), header=F)$V1
#individuals_geuvadis <- data.table::fread(glue('{project_dir}/metadata/{dataset}_individuals.txt'), header=F)$V1
individuals_99 <- data.table::fread(glue('{project_dir}/metadata/99_individuals.txt'), header=F)$V1
```

```{r}
valid_individuals <- individuals_99[individuals_99 %in% individuals_1kg]
write.table(valid_individuals, file=glue('{project_dir}/metadata/valid_{dataset}_individuals.txt'), quote=F, row.names=F, col.names=F)
```


```{r}
enformer_parameters_json <- list()

# '/lus/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan/TFpred_pipeline/metadata/individuals.txt'
enformer_parameters_json[['individuals']] <- glue('{project_dir}/metadata/valid_{dataset}_individuals.txt')
enformer_parameters_json[['n_individuals']] <- -1
enformer_parameters_json[['project_dir']] <- as.character(project_dir)
enformer_parameters_json[['interval_list_file']] <- predictor_file
enformer_parameters_json[['prediction_data_name']] <- dataset
enformer_parameters_json[['transcription_factor']] <- TF
enformer_parameters_json[['date']] <- data_date
enformer_parameters_json[['create_hdf5_file']] <- FALSE
enformer_parameters_json[['exclude_regions']] <- TRUE
enformer_parameters_json[['batch_individuals']] <- 20
enformer_parameters_json[['vcf_split']] <- TRUE
enformer_parameters_json[['vcf_files']] <- vcf_files

#enformer_parameters_json[['vcf_file']] <- "/lus/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan/genotypes/prj6_genotypes/merged_phased_SNPs.vcf.gz"

enformer_parameters_json[['sub_dir']] <- TRUE
enformer_parameters_json[['use_parsl']] <- TRUE
enformer_parameters_json[['model_path']] <- "/lus/grand/projects/covid-ct/imlab/data/enformer/raw"
enformer_parameters_json[['hg38_fasta_file']] <- "/lus/grand/projects/covid-ct/imlab/data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta"
enformer_parameters_json[['metadata_dir']] <- "/lus/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan/TFPred_pipeline/config_files"
enformer_parameters_json[['output_dir']] <- "enformer_predictions"
enformer_parameters_json[['sequence_source']] <- "personalized"
enformer_parameters_json[['predictions_log_dir']] <- "predictions_log"
enformer_parameters_json[['batch_size']] <- 1000
enformer_parameters_json[['predict_on_n_regions']] <- -1
enformer_parameters_json[['write_log']] <- list('logdir' = glue('job_logs'), 'logtypes' = list('memory'=F, 'error'=T, 'time'=F, 'cache'=F))
enformer_parameters_json[['parsl_parameters']] <- list("job_name"=glue("enformer_predict_{dataset}_{TF}"), "num_of_full_nodes"=5, "walltime"="12:00:00", "min_num_blocks"=0, "max_num_blocks"=10, "queue"="preemptable", 'hpc'='polaris')

write(
    jsonlite::toJSON(enformer_parameters_json, na='null', pretty=TRUE, auto_unbox=T),
    file=glue('{metadata_dir}/enformer_parameters_{dataset}_{TF}.json')
)

# 
param_file <- glue('{metadata_dir}/enformer_parameters_{dataset}_{TF}.json')
param_file
```


```{r}
prediction_cmd <- glue('screen\nconda activate dl-tools\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/temi/miniconda3/envs/dl-tools/lib\npython3 {project_dir}/parallel_enformer/enformer_predict.py --param_config {param_file}')
prediction_cmd
```


## Step 4: Collect/aggregate the predictions

This aggregations section makes use of the final json file created from making predicitions to determine what to aggregate. 
The user supplies what aggregation option.

There are currently 7 valid options for aggregations:
- aggByCenter:
- aggByMean:
- aggByUpstream:
- aggByDownstream:
- aggByUpstreamDownstream:
- aggByPreCenter
- aggByPostCenter

Check that the appropriate scripts exist
```{r}
# check that the script exists
aggregation_pbs_script <- glue("{project_dir}/scripts/utilities/aggregate_predictions_pbs.sh")
aggregation_pbs_script ; file.exists(aggregation_pbs_script)
```

```{r}
aggregation_python_script <- glue("{project_dir}/scripts/utilities/aggregate_predictions.py")
aggregation_python_script ; file.exists(aggregation_python_script)
```

```{r}
aggregation_config <- glue("{project_dir}/config_files/aggregation_config_{dataset}_{TF}.json")
aggregation_config ; file.exists(aggregation_config)
```

Aggregate the predictions

```{r}
agg_center <- 'aggByCenter'
agg_precenter <- 'aggByPreCenter'
agg_postcenter <- 'aggByPostCenter'
agg_meancenter <- 'aggByMeanCenter'
agg_mean <- 'aggByMean'
agg_upstream <- 'aggByUpstream'
agg_downstream <- 'aggByDownstream'
agg_upstream_downstream <- 'aggByUpstreamDownstream'

agg_methods <- c(agg_postcenter, agg_meancenter, agg_mean, agg_upstream, agg_center, agg_downstream, agg_upstream_downstream, agg_precenter)
agg_methods <- agg_meancenter
```


I am using parsl - so I don't need qsub
```{r}
aggregate_cmd <- glue("conda activate dl-tools\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/temi/miniconda3/envs/dl-tools/lib\npython3 {aggregation_python_script} --metadata_file {aggregation_config} --agg_types \"{paste0(agg_methods, collapse = ' ')}\"")

aggregate_cmd
```

```{r}
system('qstat -u temi')
```

```{r}
hg00096 <- data.table::fread(glue('/lus/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan/TFPred_pipeline/predictions_folder/subset1KGgenomes_AR/predictions_2023-02-17/aggregated_predictions/HG00096_aggByMeanCenter_AR.csv.gz'))
hg00096 |> dim()
```



### Step 5: Testing models on these individual data

#### Stand alone script to collect prediction scores (TFScores)

```{r}
model_date <- '2023-01-24'
model_dir <- glue('{project_dir}/models')
model_id <- 'cistrome'
model_types <- c('linear', 'logistic')

individuals_data_dir <- glue('{project_dir}/predictions_folder/{dataset}_{TF}/predictions_{todays_date}/aggregated_predictions')

run_date <- todays_date
output_dir <- glue('{project_dir}/model_evaluation')
if(!dir.exists(output_dir)){
    dir.create(output_dir, recursive=T)
} else {
    print('Model evaluation directory exists.')
}

predict_on <- glue('{project_dir}/metadata/valid_subset1KGgenomes_individuals.txt')
n_individuals <- length(read.csv(predict_on, header=F)$V1)

# individuals_ground_truth_file <- glue('{project_dir}/motif_intervals/{dataset}/intervals_{run_date}/ground_truth/{dataset}_{TF}_*.txt')
# gt_file <- Sys.glob(glue('{individuals_ground_truth_file}'))
```

```{r}
#; file.exists(pbs_script)
evaluate_rscript <- glue('{project_dir}/scripts/utilities/enet_evaluate_geuvadis.R')
if(file.exists(evaluate_rscript)){print('enet evaluate R script exists.')}
```
```{r}
#; file.exists(pbs_script)
evaluate_pbs_script <- glue('{project_dir}/scripts/utilities/enet_evaluate_geuvadis.sh')
if(file.exists(evaluate_pbs_script)){print('enet evaluate pbs script exists.')}
```

```{r}
# go through each model_types and predict_ons
cmds <- c()
for(model_type in model_types){
    pbs_script <- glue('qsub -v evaluate_rscript={evaluate_rscript},model_dir={model_dir},model_id={model_id},model_type={model_type},predict_on={predict_on},individuals_data_dir={individuals_data_dir},n_individuals={n_individuals},TF={TF},run_date={model_date},output_dir={output_dir},dataset={dataset} {evaluate_pbs_script}')

    cmds <- append(pbs_script, cmds)
}
print(cmds)

```

```{r}
for(cmd in cmds){system(cmd)}
#system(pbs_script)
```

```{r}
system('qstat -u temi')
```


# Evaluating the models on Geuvadis individuals
```{r}
library(ggthemes)
library(ggsignif)
library(ROCR)
```

```{r}
#ind_names <- c('LuCaP_136', 'LuCaP_141', 'LuCaP_167', 'LuCaP_145')
individuals <- data.table::fread(glue('{project_dir}/metadata/valid_subset1KGgenomes_individuals.txt'), header=F) #'/lus/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan/TFPred_pipeline/metadata/geuvadis_individuals.txt', header=F)
ind_names <- individuals$V1#[-1]#[1:5
ind_names
```

Read in the evaluations of the models
```{r}
model_evaluation_dir <- glue('{project_dir}/model_evaluation')
```

```{r}
model_type <- 'logistic'
individual_logistic_eval <- readRDS(glue('{model_evaluation_dir}/{dataset}_{TF}_{model_type}_evaluation_{model_date}.rds'))

model_type <- 'linear'
individual_linear_eval <- readRDS(glue('{model_evaluation_dir}/{dataset}_{TF}_{model_type}_evaluation_{model_date}.rds'))
```


```{r}
# merge(
#     subset(individual_linear_eval$HG00096$aggByMean, id %in% common_regions[1:10]),
#     subset(individual_linear_eval$HG00097$aggByMean, id %in% common_regions[1:10]), 
#     by='id'
# )
```


### CWAS weights predictions
```{r}
predixcan_result_dir <- '/lus/grand/projects/covid-ct/imlab/users/temi/projects/prediXcan/output'
baca_models <- c('lasso', 'lasso.as', 'lasso.plasma', 'top1.as', 'top1.qtl', 'top1')
```

```{r}
baca_predictions <- data.table::fread(glue('{predixcan_result_dir}/geuvadis_99/{baca_models[6]}/baca_cwas_predict.txt'))
baca_predictions <- baca_predictions[, -1] |> t() %>% as.data.frame()
colnames(baca_predictions) <- baca_predictions[1, ]
baca_predictions <- baca_predictions[-1, ] %>% tibble::rownames_to_column('region')
baca_predictions$region <- gsub('\\:|\\-', '_', baca_predictions[['region']])
baca_predictions <- baca_predictions %>% dplyr::mutate(across(!region, as.numeric))
baca_predictions[1:5, 1:5] |> summary() ; baca_predictions[1:5, 1:5]
```

```{r}
loci <- read.table('/lus/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan/baca_cwas/predictors/baca_cwas_AR_regions_hg38_2023-01-27.txt', header=F)$V1
loci <- loci[!is.na(loci)]
length(loci)
```

```{r}
loci[1:20]
```

```{r}
which(cwas_top1_loci %in% loci)
```

```{r}
# read in cwas supplementary data
cwas_supp <- readxl::read_xlsx(glue('{project_dir}/metadata/cwas_supplementary_table.xlsx'), sheet=3, skip=1) %>% dplyr::select(ID, MODEL, MODELCV.PV, MODELCV.R2)
cwas_supp[1:5, ] ; cwas_supp |> dim()
```

```{r}
hg38_bed <- '/lus/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan/baca_cwas/bed_files/baca_cwas_loci_hg38.bed'
hg38_bed_files <- data.table::fread(hg38_bed, col.names=c('chr', 'hg38_start', 'hg38_end', 'hg19_id'))

hg38_bed_files <- hg38_bed_files %>% tidyr::unite('hg38_id', c('chr', "hg38_start",  "hg38_end" ))

hg38_bed_files[1:5, ]

#cwas_supp[cwas_supp$ID %in% hg38_bed_files$hg19_id, ]
```

```{r}
cwas_supp <- cwas_supp %>% dplyr::left_join(hg38_bed_files, by=c('ID' = 'hg19_id'))
cwas_supp[1:5, ] ; cwas_supp |> dim()
```

```{r}
cwas_supp_top1 <- cwas_supp %>%
    dplyr::filter(MODELCV.PV < 0.01)

cwas_supp_top1[1:5,] ; length(cwas_supp_top1$ID)
```

```{r}
cwas_top1_loci <- gsub(':|-', '_', cwas_supp_top1$hg38_id)
cwas_top1_loci[1:5] ; length(cwas_top1_loci)
```


```{r}
# tfpred_result <- individual_linear_eval[[ind]]$aggByMeanCenter
# tfpred_result[1:5, ]
```

```{r}
aggm <- 'aggByMeanCenter'

ind_names <- names(individual_linear_eval)
out <- lapply(ind_names, function(each_ind){
    a <- individual_linear_eval[[each_ind]][[aggm]]
    #print(head(a))
    colnames(a) <- c('region', each_ind)
    return(a)
})

names(out) <- ind_names
linear_agg_eval <- out %>% purrr::reduce(dplyr::inner_join, by='region')
linear_agg_eval[1:5, 1:5]
```

```{r}
common_regions <- intersect(linear_agg_eval$region, baca_predictions$region)
length(common_regions)
```

```{r}
linear_agg_eval[linear_agg_eval$region %in% common_regions[1:10], 1:5]
```

### Correlation
```{r}
dim(linear_agg_eval) ; dim(baca_predictions)
```

```{r}
tfpred_ca <- linear_agg_eval %>% tibble::column_to_rownames('region')
tfpred_ca <- tfpred_ca[common_regions, ]

cwas_ca <- baca_predictions %>% tibble::column_to_rownames('region')
cwas_ca <- cwas_ca[common_regions, ]
```

```{r}
tfpred_ca[1:5, 1:5] ; cwas_ca[1:5, 1:5]
```

```{r}
<<<<<<< HEAD
source(glue('{project_dir}/TFPred_pipeline/pipelines/utilities.R'))
=======
source(glue('{project_dir}/pipelines/utilities.R'))
>>>>>>> 8d1e50b0eb3dd8bdfc1db9105ea1984253c9762d
```

#### Correlation
```{r}
region_correlations_test <- purrr::map(1:length(common_regions), function(i){
    ca <- tfpred_ca[i, ] |> unlist() |> unname()
    da <- cwas_ca[i, ] |> unlist() |> unname() |> as.numeric()
    cor_test <- cor.test(ca, da, method='spearman')
    return(c(cor_test$p.value, cor_test$estimate))
}, .progress=T)

df_cor_test <- do.call('rbind', region_correlations_test)
colnames(df_cor_test) <- c('p_value', 'r')
rownames(df_cor_test) <- common_regions
df_cor_test[1:5, ]
```

```{r}
#par(mfrow=c(1, 2), oma = c(0, 0.5, 2, 0), mar=c(4,4,2,2))
hist(df_cor_test[, 'r']^2, main='', xlab=expression(italic(R^2) ~ ", R-squared"), cex.lab=1, col='brown')
mtext(expression("Histogram of" ~ R^2 ~ "(cor test)"), side=3, line=2, adj=0.05, cex=1.2) 
mtext(glue("CWAS scores vs. TFPred scores for {nrow(df_cor_test)} regions"), side=3, line=0, cex=1.2, adj=0.05)
```

```{r}
#par(mfrow=c(1, 2), oma = c(0, 0.5, 2, 0), mar=c(4,4,2,2))
hist(df_cor_test[, 'r'], main='', xlab=expression(italic(r)[s] ~ ", spearman correlation"), cex.lab=1, col='brown')
mtext(expression("Histogram of" ~ r[s] ~ "(cor test)"), side=3, line=2, adj=0.05, cex=1.2) 
mtext(glue("CWAS scores vs. TFPred scores for {nrow(df_cor_test)} regions"), side=3, line=0, cex=1.2, adj=0.05)
```

```{r}
# qqunif(df_cor_test[, 'p_value'], frame.plot=F, pch=21, bg='black')
# mtext(expression("qqplot of" ~ italic(p) ~ "(cor test)"), side=3, line=2, adj=0.05, cex=1.2)
# mtext(glue("CWAS scores vs. TFPred scores for {nrow(df_cor_test)} regions"), side=3, line=0, cex=1.2, adj=0.05)
```

```{r}
qq_generic(df_cor_test[, 'p_value'], distribution='uniform', neg_log10_values=T, BH=T, params_to_legend=list(x='topleft', bty = "n"), params_to_plot=list(frame.plot=F, pch=19))
mtext(expression("qqplot of" ~ italic(p) ~ "(cor test)"), side=3, line=2, adj=0.05, cex=1.2)
mtext(glue("CWAS scores vs. TFPred scores for {nrow(df_cor_test)} regions"), side=3, line=0, cex=1.2, adj=0.05)
```

#### Compare their correlations with ours
```{r}
cwas_rsq_table <- cwas_supp %>% 
    dplyr::filter(!is.na(hg38_id)) %>%
    tibble::column_to_rownames('hg38_id')
```

```{r}
length(unique(cwas_supp$hg38_id)) ; length(cwas_supp$hg38_id)
```

```{r}
a <- as.data.frame(df_cor_test)[rownames(cwas_rsq_table), 'r']^2
b <- cwas_rsq_table$MODELCV.R2

length(a) ; length(b)
```
```{r}
plot(b, a, xlab='TFPred R-squared', ylab='CWAS R-squared')
abline(lm(a ~ b))
```

```{r}
data.frame(a, b) %>%
    dplyr::filter((is.finite(a) &  is.finite(b))) %>%
    ggplot(., aes(b, a)) +
    geom_smooth()
    #geom_point() 
    
```
```{r}
summary(df_cor_test[, 'r']^2)
```

```{r}
hist(df_cor_test[, 'r']^2, main='', xlab=expression(italic(R^2) ~ ", correlation"), col='brown')
mtext(glue('Distribution of R^2 between CWAS {baca_models[6]} scores and TFPred scores \nfor {nrow(df_cor_test)} regions'), adj=0, cex=1.5)
```


```{r}
loci_corr_0.01 <- df_cor_test[which(df_cor_test[, 'p_value'] < 0.01), 'r']#[cwas_top1_loci] |> summary()
loci_corr_0.01 <- loci_corr_0.01[names(loci_corr_0.01) %in% cwas_top1_loci] #|> summary()
```

```{r}
any(is.na(loci_corr_0.01))
```

```{r}
hist(loci_corr_0.01 |> unname(), breaks=20, xlab='r, correlation', main='')
mtext('Histogram of correlation for cwas loci < 0.01 and TFPred loci < 0.01', line=1, side=3)
```


#### Significant AR CWAS associations for response to androgen deprivation therapy
```{r}
# read in cwas supplementary data
cwas_AR_adt <- readxl::read_xlsx(glue('{project_dir}/metadata/cwas_supplementary_table.xlsx'), sheet=10, skip=1) %>% dplyr::select(ID, MODEL, MODELCV.PV)
cwas_AR_adt[1:5, ] ; cwas_AR_adt |> dim()
```

```{r}
cwas_AR_adt <- cwas_AR_adt %>% dplyr::left_join(hg38_bed_files, by=c('ID' = 'hg19_id'))
cwas_AR_adt[1:5, ] ; cwas_AR_adt |> dim()
```

```{r}
cwas_AR_adt <- gsub(':|-', '_', cwas_AR_adt$hg38_id)
cwas_AR_adt[1:5] ; length(cwas_AR_adt)
```

```{r}
cwas_AR_adt_pvalues <- df_cor_test[cwas_AR_adt, ]
cwas_AR_adt_loci <- cwas_AR_adt
cor_sq_values <- df_cor_test[cwas_AR_adt_loci, 'r']
cor_sq_values
```


```{r}
par(mfrow=c(1,3), oma = c(2, 2, 7, 2), mar=c(3,3,5,2))

for(i in 1:nrow(cwas_AR_adt_pvalues)){
    x <- tfpred_ca[cwas_AR_adt_loci[i], ] |> unlist() |> unname() |> as.numeric()
    y <- cwas_ca[cwas_AR_adt_loci[i], ] |> unlist() |> unname() |> as.numeric()

    #txt <- paste(cwas_AR_adt_loci[i], '\n p = ', formatC(cwas_AR_adt_pvalues[i], format = "e", digits = 2), ', ', expression(R^2), ' = ', round(cor_sq_values[i] |> unname(), 2))

    txt_variables <- list(lv = cwas_AR_adt_loci[i], pv=formatC(cwas_AR_adt_pvalues[i], format = "e", digits = 2), cv=round(cor_sq_values[i] |> unname(), 2))

    txt <- bquote(atop(.(txt_variables$lv), italic(p) ~ '=' ~ .(txt_variables$pv) ~ ',' ~ italic(r[s]) ~ ' = ' ~ .(txt_variables$cv)))

    plot(x, y,
        frame.plot=F, xlab='', ylab='', pch=21, col='black', bg='brown',
        main=txt
    )
    abline(lm(y ~ x), col='red')
}

mtext(glue('CWAS model scores vs {aggm} TFPred scores \nfor significant AR CWAS associations for response to \nandrogen deprivation therapy'), side=3, adj=0, cex=1.5, outer=T)
mtext(glue('CWAS predictions'), side=2, adj=0.5, cex=1, outer=T)
mtext(glue('TFPred scores'), side=1, adj=0.5, cex=1, outer=T)
```

#### scatterplot of regions

```{r}
cwas_supp_top1 <- cwas_supp %>%
    dplyr::arrange(desc(MODELCV.R2)) %>%
    dplyr::slice_max(MODELCV.R2, n=6)

cwas_supp_top1[1:5,] ; length(cwas_supp_top1$ID)
```

```{r}
cwas_top1_loci <- gsub(':|-', '_', cwas_supp_top1$hg38_id)
cwas_top1_loci[1:5] ; length(cwas_top1_loci)
```
```{r}
tfpred_ca[1:5, 1:5] ; cwas_ca[1:5, 1:5]
```

```{r}
cwas_AR_top6_pvalues <- df_cor_test[cwas_top1_loci, ]
cwas_AR_top6_loci <- cwas_top1_loci
cor_sq_values <- df_cor_test[cwas_top1_loci, 'r']
cor_sq_values
```

```{r}
par(mar = c(4, 4, 6, 4))

picked_loci <- 'chr4_96092999_96093499'
picked_loci_i <- which(cwas_AR_top6_loci == picked_loci)
x <- tfpred_ca[picked_loci, ] |> unlist() |> unname() |> as.numeric()
y <- cwas_ca[picked_loci, ] |> unlist() |> unname() |> as.numeric()

txt_variables <- list(lv = cwas_AR_top6_loci[picked_loci_i], pv=formatC(cwas_AR_top6_pvalues[picked_loci_i], format = "e", digits = 2), cv=round(cor_sq_values[picked_loci_i] |> unname(), 2))

txt <- bquote(italic(p) ~ '=' ~ .(txt_variables$pv) ~ ',' ~ italic(r[s]) ~ '=' ~ .(txt_variables$cv))

plot(x, y,
    frame.plot=F, pch=21, col='black', bg='brown', xlab=glue('TFPred scores'), ylab=glue('CWAS scores')
)
abline(lm(y ~ x), col='red')
mtext(glue('CWAS scores vs. TFPred scores for \nloci {picked_loci}'), side=3, adj=0, cex=1.5, line=2)
mtext(txt, side=3, adj=0, cex=1.5, line=0)

```

```{r}
par(mfrow=c(3,2), oma = c(2, 2, 7, 2), mar=c(3,3,5,2))

for(i in 1:nrow(cwas_AR_top6_pvalues)){
    x <- tfpred_ca[cwas_AR_top6_loci[i], ] |> unlist() |> unname() |> as.numeric()
    y <- cwas_ca[cwas_AR_top6_loci[i], ] |> unlist() |> unname() |> as.numeric()

    #txt <- paste(cwas_AR_adt_loci[i], '\n p = ', formatC(cwas_AR_adt_pvalues[i], format = "e", digits = 2), ', ', expression(R^2), ' = ', round(cor_sq_values[i] |> unname(), 2))

    txt_variables <- list(lv = cwas_AR_top6_loci[i], pv=formatC(cwas_AR_top6_pvalues[i], format = "e", digits = 2), cv=round(cor_sq_values[i] |> unname(), 2))

    txt <- bquote(atop(.(txt_variables$lv), italic(p) ~ '=' ~ .(txt_variables$pv) ~ ',' ~ italic(r[s]) ~ '=' ~ .(txt_variables$cv)))

    plot(x, y,
        frame.plot=F, xlab='', ylab='', pch=21, col='black', bg='brown',
        main=txt
    )
    abline(lm(y ~ x), col='red')
}

mtext(glue('CWAS scores vs. TFPred scores for \ntop {nrow(cwas_AR_top6_pvalues)} loci by CWAS R-squared'), side=3, adj=0, cex=1.5, outer=T, line=1)
mtext(glue('CWAS scores'), side=2, adj=0.5, cex=1, outer=T)
mtext(glue('TFPred scores'), side=1, adj=0.5, cex=1, outer=T)
```

### Scatterplot for one individual
```{r}
ind <- 'HG00096'
```
```{r}
lowest_pvalues <- sort(region_correlations_test, decreasing=F)[1:8]
lowest_pvalues_loci <- names(lowest_pvalues)
```

```{r}
cor_values <- region_correlations[lowest_pvalues_loci]
cor_values
```

```{r}

par(mfrow=c(4,2), oma = c(2, 2, 5, 0), mar=c(4,4,5,2))

for(i in 1:length(lowest_pvalues_loci)){
    x <- tfpred_ca[lowest_pvalues_loci[i], ] |> unlist() |> unname() |> as.numeric()
    y <- cwas_ca[lowest_pvalues_loci[i], ] |> unlist() |> unname() |> as.numeric()

    txt <- paste(lowest_pvalues_loci[i], ', p = ', formatC(lowest_pvalues[i], format = "e", digits = 2), ', ', expression(r), ' = ', round(cor_values[i] |> unname(), 2))

    print(txt)
    plot(x, y,
        frame.plot=F, xlab='', ylab='', pch=21, col='black', bg='brown',
        main=txt
    )
    abline(lm(y ~ x), col='red')
    #abline(lm(x ~ y), col='red')
}

mtext(glue('CWAS {baca_models[6]} model scores vs {aggm} TFPred scores \nfor top 4 regions by pvalues across {length(ind_names)} individuals'), side=3, adj=0, cex=1.5, outer=T)
mtext(glue('CWAS predictions'), side=2, adj=0.5, cex=1, outer=T)
mtext(glue('TFPred scores'), side=1, adj=0.5, cex=1, outer=T)
```

#### correlation across individuals

```{r}
cwas_supp_top1 <- cwas_supp %>%
    dplyr::arrange(desc(MODELCV.R2)) %>%
    dplyr::slice_max(MODELCV.R2, n=6)

cwas_supp_top1[1:5,] ; length(cwas_supp_top1$ID)
```

```{r}
cwas_top1_loci <- gsub(':|-', '_', cwas_supp_top1$hg38_id)
cwas_top1_loci[1:5] ; length(cwas_top1_loci)
```
```{r}
tfpred_ca[1:5, 1:5] ; cwas_ca[1:5, 1:5]
```

```{r}
ind_cor_loci <- sapply(colnames(tfpred_ca), function(each_ind){
    cor(tfpred_ca[common_regions, each_ind], cwas_ca[common_regions, each_ind], method='spearman')
})
```

```{r}
test_loci <- 'chr1_11151993_11152693'
tfpred_ca[test_loci, ] |> unlist() |> unname() ; cwas_ca[test_loci, ] |> unlist() |> unname()
```

```{r}
a <- cwas_ca[test_loci, ] |> unlist() |> unname()
b <- tfpred_ca[test_loci, ] |> unlist() |> unname()
```

```{r}
a[a < 0.1]
b[b < 0.1]
```

```{r}
dt <- cbind(a, b)
dt <- dt[dt[, 'b'] < 0.1, ] |> as.data.frame()
```

```{r}
with(dt, plot(a, b, xlab='cwas', ylab='TFPred'))
```

```{r}
dt %>% ggplot() + aes(a, b) + geom_point() + geom_smooth()
```

```{r}
cor(a, b, method='pearson')
```

```{r}
test_loci %in% row.names(cwas_ca)
```

```{r}
hg38_bed_files[hg38_bed_files$hg19_id == 'chr1:11212050-11212750', ]
```


```{r}
barplot(ind_cor_loci, xaxt='n', xlab='individual', ylab=expression(italic(r)*', correlation'), cex.lab=1, col=ifelse(ind_cor_loci < 0, 'brown', 'blue'))
mtext(glue('Correlation between CWAS {baca_models[6]} model scores and TFPred scores \nacross {nrow(tfpred_ca)} regions for 99 individuals'),line=0, cex=1.5, adj=0)
```


#### Shuffling individuals in CWAS predictions
```{r}
# permute the individuals for CWAS prediction

permutation_matrix <- matrix(NA, nrow=nrow(cwas_ca), ncol=1)

for(i in 1:ncol(permutation_matrix)){
    pm <- sample(1:ncol(cwas_ca), ncol(cwas_ca))
    temp_cwas_ca <- cwas_ca[, pm]

    rc <- purrr::map(1:length(common_regions), function(i){
        ca <- tfpred_ca[i, ] |> unlist() |> unname()
        da <- temp_cwas_ca[i, ] |> unlist() |> unname()
        return(cor(ca, da))
    }, .progress=T)

    rc <- unlist(rc) |> unname()
    permutation_matrix[ , i] <- rc
}

permutation_matrix[1:5, ]
```

```{r}
hist(permutation_matrix[, 1])
```

```{r}
#permutation_test <- matrix(NA, nrow=nrow(cwas_ca), ncol=2)

pm <- sample(1:ncol(cwas_ca), ncol(cwas_ca))
temp_cwas_ca <- cwas_ca[, pm] # shuffle the cwas data

permutation_test <- purrr::map(1:length(common_regions), function(i){
    ca <- tfpred_ca[i, ] |> unlist() |> unname()
    da <- temp_cwas_ca[i, ] |> unlist() |> unname()
    cor_test <- cor.test(ca, da, method='spearman', exact=F)
    return(c(cor_test$p.value, cor_test$estimate))
}, .progress=T)

permutation_test <- do.call('rbind', permutation_test)
permutation_test[, 1] <- permutation_test[, 1]
permutation_test[, 2] <- permutation_test[, 2]
colnames(permutation_test) <- c('p_value', 'r')
rownames(permutation_test) <- common_regions
permutation_test[1:5, ]
```


```{r}
#par(mfrow=c(1, 2), oma = c(0, 0.5, 2, 0), mar=c(4,4,2,2))
hist(permutation_test[, 'r']^2, main='', xlab=expression(italic(R^2) ~ ", R-squared"), cex.lab=1, col='brown', xlim=c(0, 1))
mtext(expression("Histogram of" ~ R^2 ~ "(cor test) - permutation test"), side=3, line=2, adj=0.05, cex=1.2) 
mtext(glue("CWAS scores vs. TFPred scores for {nrow(permutation_test)} regions"), side=3, line=0, cex=1.2, adj=0.05)
```

```{r}
#par(mfrow=c(1, 2), oma = c(0, 0.5, 2, 0), mar=c(4,4,2,2))
hist(permutation_test[, 'r'], main='', xlab=expression(italic(r)[s] ~ ", spearman correlation"), cex.lab=1, col='brown')
mtext(expression("Histogram of" ~ r[s] ~ "(cor test) - permutation test"), side=3, line=2, adj=0.05, cex=1.2) 
mtext(glue("CWAS scores vs. TFPred scores for {nrow(permutation_test)} regions"), side=3, line=0, cex=1.2, adj=0.05)
```

```{r}
qq_generic(permutation_test[, 'p_value'], distribution='uniform', neg_log10_values=T, BH=T, params_to_legend=list(x='topleft', bty = "n"), params_to_plot=list(frame.plot=F, pch=19))
mtext(expression("qqplot of" ~ italic(p) ~ "(cor test) - permutation test"), side=3, line=2, adj=0.05, cex=1.2)
mtext(glue("CWAS scores vs. TFPred scores for {nrow(permutation_test)} regions"), side=3, line=0, cex=1.2, adj=0.05)
```


```{r}
par(mfrow=c(1,1), oma = c(2, 2, 5, 0), mar=c(4,4,5,2))

for(i in 1:ncol(permutation_matrix)){
    x <- permutation_matrix[, i][!is.na(permutation_matrix[, i])]
    hist(x, main='', xlab=expression(italic(r) ~ ", correlation"), col='brown')
    mtext(glue('permutation {i}'), adj=0, cex=1.5)

}

mtext(glue('Distribution of correlations between CWAS scores and TFPred scores \nfor {length(region_correlations)} regions'), adj=0, cex=1.5, outer=T)

```

```{r}

#layout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE), heights=c(6,6), widths=c(6, 6))


plots_list <- list()

plotit <- function(x, i){
    par(mfrow=c(1, 2), oma = c(0, 0.5, 2, 0), mar=c(4,4,2,2))
    hist(x, main='', xlab=expression(italic(p) ~ ", p-value"), cex.lab=1, col='brown')
    qqunif(x, frame.plot=F, pch=21,bg='black')
    mtext(glue('permutation test'), side=3, line=-1, adj=0.05, cex=1.2, outer=TRUE)
}


for(i in 1:ncol(permutation_pvalues)){

    x <- permutation_pvalues[, i][!is.na(permutation_pvalues[, i])]
    plots_list[[i]] <- function(){plotit(x=x, i=i)}
    #mtext(glue('permutation {i}'), side=3, line=-1, adj=0.05, cex=1.2, outer=T)

}

```

```{r}
for(i in 1:length(plots_list)){
    plots_list[[i]]()
}
```

```{r}
plot(1:20)
p1 <- recordPlot()
```

```{r}
dev.off()
```



#### Motifs in CWAS loci

```{r}
library(GenomicRanges)
```

```{r}
training_motifs <- glue('{project_dir}/motif_intervals/cistrome/intervals_2023-01-24/predictors/cistrome_AR_37212.txt')
training_motifs <- data.table::fread(training_motifs, header=F)$V1
training_motifs <- do.call('rbind', strsplit(training_motifs, '_')) |> as.data.frame()
colnames(training_motifs) <- c('chr', 'start', 'end')
training_motifs <- training_motifs %>% dplyr::mutate(start=as.numeric(start), end=as.numeric(end))
training_motifs[1:5, ]
```
```{r}
cwas_loci <- do.call('rbind', strsplit(cwas_supp$hg38_id, '_')) |> as.data.frame()
colnames(cwas_loci) <- c('chr', 'start', 'end')
cwas_loci <- cwas_loci[!is.na(cwas_loci[,2]) & !is.na(cwas_loci[,3]), ]
cwas_loci[1:5, ]
```

```{r}
training_motifs_granges <- with(training_motifs, GRanges(chr, IRanges(as.numeric(start), as.numeric(end)), strand='*', score=0))
```

```{r}
cwas_loci_granges <- with(cwas_loci, GRanges(chr, IRanges(as.numeric(start), as.numeric(end)), strand='*', score=0))
```

```{r}
loci_overlaps <- GenomicRanges::findOverlaps(query=training_motifs_granges, subject=cwas_loci_granges, type='any')
```

```{r}
cwas_loci_granges[subjectHits(loci_overlaps), ]
```

```{r}
training_motifs_granges[queryHits(loci_overlaps), ]
```


### Are the clumpings due to a specific SNP?

Filter out the snps in this region
```{r}
test_loci <- 'chr4_96092999_96093499'
test_loci_split <- strsplit(test_loci, '_') |> unlist()
```

```{r}
hg38_snps_file <- glue('{project_dir}/../baca_cwas/snps/hg38_snps.bed')
cmd <- glue('grep {test_loci_split[1]} {hg38_snps_file} | grep {test_loci_split[2]} | grep {test_loci_split[3]}')
cmd
```

```{r}
snps_dt <- system(cmd, intern = TRUE) %>% strsplit(., '\t') %>% do.call('rbind', .) |> as.data.frame() %>% dplyr::mutate(V2 = as.numeric(V2), V3 = as.numeric(V3))
colnames(snps_dt) <- c('chr', 'start', 'end', 'snp_id', 'loci')
snps_dt[1:5, ]
```

Filter the training motifs

```{r}
motif_in_loci <- subset(training_motifs, chr=='chr4' & start >= 96092999 & end <= 96093499)
motif_in_loci
```

The motif is not in the define peak
```{r}
snp_in_motif <- subset(snps_dt, start >= motif_in_loci$start & end <= motif_in_loci$end)
snp_in_motif
```

Calculate distance of snps to motifs

```{r}
snps_dt <- snps_dt %>% dplyr::mutate(snp_dist = motif_in_loci$start - start, query = paste(chr, start, sep=':'))
snps_dt
```

```{r}
write.table(snps_dt, glue('{project_dir}/analysis/test_variants.txt'), sep='\t')
```

<<<<<<< HEAD
```{r}
data.table::fread(glue('{project_dir}/analysis/test_variants.txt'), row.names=F) %>% tibble::column_to_rownames('V1')
```

=======
>>>>>>> 8d1e50b0eb3dd8bdfc1db9105ea1984253c9762d
Nominating snps

```{r}
#library(vcfR)
# chr4_vcf <- vcfR::read.vcfR('/lus/grand/projects/covid-ct/imlab/data/GEUVADIS/vcf_snps_only/ALL.chr4.shapeit2_integrated_SNPs_v2a_27022019.GRCh38.phased.vcf.gz', verbose=F)
```

```{r}
'rs7686416'
```
```{r}
glue('conda activate compbio-tools\nbcftools view -H -r {paste0(snps_dt$bcf_r, collapse=\',\')} -s {paste0(ind_names, collapse=",")} /lus/grand/projects/covid-ct/imlab/data/GEUVADIS/vcf_snps_only/ALL.chr4.shapeit2_integrated_SNPs_v2a_27022019.GRCh38.phased.vcf.gz')
```

```{python}
vcf_file = '/lus/grand/projects/covid-ct/imlab/data/GEUVADIS/vcf_snps_only/ALL.chr4.shapeit2_integrated_SNPs_v2a_27022019.GRCh38.phased.vcf.gz'
```

```{python}
import cyvcf2
import pandas as pd
import os
import numpy as np
```

```{python}
os.getcwd()
```

```{python}
test_variants = pd.read_table('../analysis/test_variants.txt')
test_variants
```

```{python}
individuals = pd.read_table('/lus/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan/TFPred_pipeline/metadata/valid_subset1KGgenomes_individuals.txt', header=None)[0].to_list()
individuals[0:5], len(individuals)
```

```{python}
vcf_chr = cyvcf2.cyvcf2.VCF(vcf_file, samples=individuals)
```


```{python}
def find_variants_in_vcf_file(cyvcf2_object, samples, queries):

    """
    Given a cyvcf2 object and a kipoiseq.Interval object, as well as a list of samples, extract the variants for the samples for the intervals.
    Parameters:
        cyvcf2_object: A cyvcf2 object
        interval_object: a kiposeq.Interval object
            should have `chrom`, `start`, and `end` attributes
        samples: list
            a list of samples: [a, b, c]
            At least one of these samples should be in the vcf file. 
    Returns: dict
        chr: the chromosome
        position: the list of positions
        sample: the samples and variants information
    """

    #n_samples = len(samples)

    # check that samples are in the vcf file
    # if not set(samples).issubset(cyvcf2_object.samples):
    #     raise Exception(f'[ERROR] Fatal. Some samples are not in the VCF file.')

    variants_dictionary = {}

    for query in queries:
        query_dictionary = {}
        query_dictionary['chr'] = query.split(':')[0]
        query_dictionary['positions'] = tuple(variant.POS for variant in cyvcf2_object(query))

        if not query_dictionary['positions']:
            print(f'{query} does not exist in vcf file')
            continue
        else:
            for i, sample in enumerate(samples):
                try:
                    if sample in cyvcf2_object.samples:
                        sample_variants = tuple([variant.genotypes[i][0:2], variant.gt_bases[i].split('|')] for variant in cyvcf2_object(query))
                        # return(sample_variants)
                        sample_alleles = ['_'.join(sample_variants[i][1]) for i in range(len(sample_variants))]
                        query_dictionary[sample] = sample_alleles
                except UserWarning:
                    print(f'[WARNING] {sample} is not in the VCF file.')
                    continue
        variants_dictionary[query] = pd.DataFrame(query_dictionary)

    output = pd.DataFrame(np.vstack(list(variants_dictionary.values())))
    colnames = ['chr', 'position']
    colnames.extend(samples)
    output.columns = colnames
    return(output)
```


```{python}
queries = [f"{test_variants['chr'].tolist()[i]}:{test_variants['start'].tolist()[i]}-{test_variants['end'].tolist()[i]}" for i in range(test_variants.shape[0])]
queries
```
```{python}
individual_snps = find_variants_in_vcf_file(vcf_chr, samples=individuals, queries=queries)
```

```{python}
output_snps = individual_snps.merge(test_variants.loc[:,['chr', 'start', 'snp_id']], left_on=['chr', 'position'], right_on=['chr', 'start'], how='inner')
output_snps.drop('start', axis=1, inplace=True)
output_snps = output_snps[['chr', 'position', 'snp_id'] + [c for c in output_snps if c not in ['chr', 'position', 'snp_id']]]
output_snps.head()
```

```{python}
output_snps.to_csv(f'/lus/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan/TFPred_pipeline/analysis/geuvadis_99_variants.txt', sep='\t', index=False)
```

Back to R...
```{r}
snp_details <- data.table::fread(glue('{project_dir}/analysis/geuvadis_99_variants.txt'))#snp_details <- snp_details %>% tidyr::unite('haps', hap1:hap2, sep='', remove=F)
snp_details[1:5, ]
```

```{r}
individuals <- individuals |> unlist() |> unname()
<<<<<<< HEAD
unique_snps <- snp_details %>% dplyr::select(all_of(individuals[1])) %>% unlist() |> unname() |> unique()
=======
unique_snps <- snp_details %>% dplyr::select(.data[[individuals[1]]]) %>% unlist() |> unname() |> unique()
>>>>>>> 8d1e50b0eb3dd8bdfc1db9105ea1984253c9762d
```

```{r}
allele_dosage_matrix <- apply(snp_details[, -c(1:3)], 1, function(each_row){
    unique_snps <- unique(each_row |> unlist() |> unname())
    dosage_mappings <- strsplit(unique_snps, '_') |> unlist() |> unique()
    each_row <- sub('_', '', each_row)
    each_dosage <- ifelse(each_row == strrep(dosage_mappings[1], 2), 0, 
        ifelse(each_row == strrep(dosage_mappings[2], 2), 2, 
            1))
    names(each_dosage) <- each_row
    return(each_dosage)

}) |> as.data.frame()

rownames(allele_dosage_matrix) <- colnames(snp_details[, -c(1:3)])
colnames(allele_dosage_matrix) <- snp_details$snp_id
allele_dosage_matrix <- allele_dosage_matrix %>% tibble::rownames_to_column('sample')
allele_dosage_matrix[1:5, ]
```

```{r}
picked_loci <- 'chr4_96092999_96093499'
<<<<<<< HEAD
picked_loci_i <- which(rownames(tfpred_ca) == picked_loci)
=======
picked_loci_i <- which(cwas_AR_top6_loci == picked_loci)
>>>>>>> 8d1e50b0eb3dd8bdfc1db9105ea1984253c9762d
x <- tfpred_ca[picked_loci, ] |> unlist() |> as.data.frame() %>% tibble::rownames_to_column('sample')
colnames(x)[2] <- 'TFPred_score'
x[1:5,]
```

```{r}
xdt <- merge(x, allele_dosage_matrix, by='sample')
xdt <- xdt[, -1]
xdt[1:5, ]
```

```{r}
<<<<<<< HEAD
tst <- lm(TFPred_score ~ ., data=xdt) |> summary()
```

```{r}
tst_dt <- coef(tst) %>% as.data.frame() %>% tibble::rownames_to_column('snp')
tst_dt <- tst_dt[-1, ] %>% dplyr::select(all_of(c('snp', 'Estimate', 'Pr(>|t|)'))) %>% dplyr::rename(pvalue=3, beta=2)
tst_dt
```

```{r}
plot(-log10(tst_dt$pvalue), frame.plot=F, pch=19, xaxt='n', ylab='-log10(p)', xlab='snp')
axis(1, at = 1:nrow(tst_dt), labels = F)
text(x = 1:nrow(tst_dt), y = par("usr")[3] - 0.45,
     labels = tst_dt$snp,xpd = NA,
     ## Rotate the labels by 35 degrees.
     srt = 35,
     cex = 0.8, adj = 1.2)
```

```{r}
with(tst_dt, plot(-log10(pvalue), beta, pch=19, frame.plot=F, xlim=c(0, 60)))
# pos_vector <- rep(4, nrow(tst_dt))
# pos_vector[-log10(tst_dt$pvalue) < 10] <- 3
with(tst_dt, text(-log10(pvalue) + 4, beta, labels=snp))
mtext(glue('p-values and effects of nearby known SNPs on TFPred score of {picked_loci}'), side=3, line=2, adj=0.05, cex=1.2)
=======
lm(TFPred_score ~ ., data=xdt) |> summary()
>>>>>>> 8d1e50b0eb3dd8bdfc1db9105ea1984253c9762d
```

```{r}
for(rs in colnames(allele_dosage_matrix)[-1]){
    print(rs)
    print(
        xdt %>% 
        ggplot(., aes(x=factor(.data[[rs]]), y=TFPred_score, fill=.data[[rs]])) + 
        geom_boxplot() + 
        geom_jitter() + 
        theme_minimal() + 
<<<<<<< HEAD
        labs(x=rs, y='TFPred score', title=picked_loci)
=======
        labs(x=rs, y='TFPred score', title='chr4:96093166-96093166')
>>>>>>> 8d1e50b0eb3dd8bdfc1db9105ea1984253c9762d
    )
}

```

```{r}
<<<<<<< HEAD
xdt %>% ggplot(., aes(x=haps, y=TFPred_score, fill=haps)) + geom_boxplot() + geom_jitter() + theme_minimal() + labs(x='rs10516988', y='TFPred score', title='chr4:96093166-96093166')
=======
xdt %>% ggplot(., aes(x=haps, y=TFPred_score, fill=haps)) + geom_boxplot() + geom_jitter() + theme_minimal() + labs(x='rs7686416', y='TFPred score', title='chr4:96093166-96093166')
>>>>>>> 8d1e50b0eb3dd8bdfc1db9105ea1984253c9762d
```

```{r}
xdt %>% dplyr::group_by(haps) %>% summarize(mean_TFPred_score = mean(TFPred_score))
```

```{r}
<<<<<<< HEAD
snp_effects_dt <- lapply(colnames(xdt)[-1], function(rs){
    ty <- xdt[, c('TFPred_score', rs)]
    ty <- lm(ty[, 1] ~ ty[, 2]) |> summary() |> coef()
    return(ty[2, c(1,4)])
}) %>% do.call('rbind', .) %>% cbind(colnames(xdt)[-1], .) %>% as.data.frame() %>% dplyr::rename(snp=1, beta=2, pvalue=3) %>% dplyr::mutate(beta=as.numeric(beta), pvalue=as.numeric(pvalue))

snp_effects_dt
```

```{r}
test_variants <- data.table::fread('/lus/grand/projects/TFXcan/imlab/users/temi/projects/TFXcan/TFPred_pipeline/analysis/test_variants.txt') %>% dplyr::select(snp_id, snp_dist, query)
test_variants
```

```{r}
snp_effects_dt <- merge(snp_effects_dt, test_variants, by.x='snp', by.y='snp_id')
snp_effects_dt <- snp_effects_dt[order(snp_effects_dt$snp_dist), ] %>% dplyr::mutate(pvalue_adj = p.adjust(pvalue,method='fdr'))
snp_effects_dt 
```

```{r}
with(snp_effects_dt, base::plot(snp_dist, -log10(pvalue_adj), pch=19, frame.plot=F, ylim=c(0, 60), xlab='SNP position from center of loci', ylab='-log10(p)'))
abline(h=-log10(0.001), col='red')
mtext(glue('p-values and effects of nearby known SNPs \non TFPred score of {picked_loci}'), side=3, line=1, adj=0, cex=1.2)
legend('topright', col='red', legend='fdr, p < 0.001', lty=1)
```

```{r}
msigsnp <- snp_effects_dt[which.min(snp_effects_dt$pvalue_adj)]

xdt %>% 
        ggplot(., aes(x=factor(.data[[msigsnp]]), y=TFPred_score, fill=.data[[msigsnp]])) + 
        geom_boxplot() + 
        geom_jitter() + 
        theme_minimal() + 
        labs(x=msigsnp, y='TFPred score', title=picked_loci)
```

```{r}
=======
>>>>>>> 8d1e50b0eb3dd8bdfc1db9105ea1984253c9762d
x_ <- ifelse(xdt$haps == 'CC', 0, ifelse(xdt$haps == 'TT', 2, 1))
y_ <- xdt$TFPred_score

lm(y_ ~ x_) |> summary()
```