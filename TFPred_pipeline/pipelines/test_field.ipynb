{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os, sys, json\n",
    "from datetime import date\n",
    "import parsl\n",
    "from parsl.app.app import python_app\n",
    "import subprocess\n",
    "import argparse\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " '/lus/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan/TFpred_pipeline')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whereis_script = '/lus/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan/TFpred_pipeline/' #os.path.dirname(sys.argv[0]) # or os.path.dirname(__file__)\n",
    "os.chdir(whereis_script), os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = f'/lus/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan/TFpred_pipeline'\n",
    "predictions_dir = f'{project_dir}/prediction_folder/enformer_predictions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mtdata = './aggregation_config_freedman_FOXA1.json'\n",
    "\n",
    "agg_type = 'aggByMean'\n",
    "TF = 'FOXA1'\n",
    "dataset = 'cistrome'\n",
    "data_date = '2023-01-11'\n",
    "\n",
    "script_path = f'{project_dir}/pipelines'\n",
    "utils_path = os.path.join(script_path, 'utilities')\n",
    "sys.path.append(utils_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chr12_57355008_57355017']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one h5 file\n",
    "# chr12_57355008_57355017_predictions.h5\n",
    "# chr8_133158323_133158332_predictions.h5\n",
    "# chr2_201510974_201510983_predictions.h5\n",
    "# chr11_133631801_133631810_predictions.h5\n",
    "one_file = f'./prediction_folder/enformer_predictions/cistrome_FOXA1/predictions_2023-01-11/cistrome/chr12_57355008_57355017_predictions.h5'\n",
    "f = h5py.File(one_file, 'r')\n",
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = ['chr12_57355008_57355017', 'chr8_133158323_133158332', 'chr2_201510974_201510983', 'chr11_133631801_133631810']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = f['chr12_57355008_57355017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 5313)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_db = f'{whereis_script}/prediction_folder/predictions_db'\n",
    "os.makedirs(h5_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./prediction_folder/enformer_predictions/cistrome_FOXA1/predictions_2023-01-11/cistrome/chr12_57355008_57355017_predictions.h5',\n",
       " './prediction_folder/enformer_predictions/cistrome_FOXA1/predictions_2023-01-11/cistrome/chr8_133158323_133158332_predictions.h5',\n",
       " './prediction_folder/enformer_predictions/cistrome_FOXA1/predictions_2023-01-11/cistrome/chr2_201510974_201510983_predictions.h5',\n",
       " './prediction_folder/enformer_predictions/cistrome_FOXA1/predictions_2023-01-11/cistrome/chr11_133631801_133631810_predictions.h5']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5files = [f'./prediction_folder/enformer_predictions/cistrome_FOXA1/predictions_2023-01-11/cistrome/{i}_predictions.h5' for i in test_predictions]\n",
    "h5files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs_list = log_data.loc[log_data['sequence_type'] == pred_type, ].motif.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                      motif individual     status sequence_type\n",
       " 0   chr18_60106170_60106179   cistrome  completed           ref\n",
       " 1     hr1_23967233_23967242   cistrome  completed           ref\n",
       " 2  chr3_109912469_109912478   cistrome  completed           ref\n",
       " 3   chr16_58215584_58215593   cistrome  completed           ref\n",
       " 4   chr10_59714479_59714488   cistrome  completed           ref,\n",
       " (46888, 4))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data = pd.read_csv(f'{project_dir}/prediction_folder/predictions_log/{dataset}_{TF}/predictions_log_{data_date}.csv')\n",
    "log_data.iloc[0:5, ], log_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46888"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compress data into one hdf5 file\n",
    "# you alse need to save the name of the files/motifs\n",
    "motifs_list = list(set(log_data.motif.values.tolist()))\n",
    "len(motifs_list) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./prediction_folder/enformer_predictions/cistrome_FOXA1/predictions_2023-01-11/cistrome/chr4_45874952_45874961_predictions.h5',\n",
       " './prediction_folder/enformer_predictions/cistrome_FOXA1/predictions_2023-01-11/cistrome/chr1_44660554_44660563_predictions.h5',\n",
       " './prediction_folder/enformer_predictions/cistrome_FOXA1/predictions_2023-01-11/cistrome/chr4_150900878_150900887_predictions.h5',\n",
       " './prediction_folder/enformer_predictions/cistrome_FOXA1/predictions_2023-01-11/cistrome/chr3_137061588_137061597_predictions.h5',\n",
       " './prediction_folder/enformer_predictions/cistrome_FOXA1/predictions_2023-01-11/cistrome/chr10_56496697_56496706_predictions.h5']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5files = [f'./prediction_folder/enformer_predictions/cistrome_FOXA1/predictions_2023-01-11/cistrome/{i}_predictions.h5' for i in motifs_list]\n",
    "h5files[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46887"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first filter if the file is present in the folder\n",
    "h5files = [dt for dt in h5files if os.path.isfile(dt) ]\n",
    "len(h5files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr4_45874952_45874961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1_44660554_44660563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr4_150900878_150900887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr3_137061588_137061597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr10_56496697_56496706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46883</th>\n",
       "      <td>chr21_42801693_42801702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46884</th>\n",
       "      <td>chr14_102154568_102154577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46885</th>\n",
       "      <td>chr4_155339892_155339901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46886</th>\n",
       "      <td>chr1_220612585_220612594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46887</th>\n",
       "      <td>chr12_93470276_93470285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46888 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           motif\n",
       "0         chr4_45874952_45874961\n",
       "1         chr1_44660554_44660563\n",
       "2       chr4_150900878_150900887\n",
       "3       chr3_137061588_137061597\n",
       "4        chr10_56496697_56496706\n",
       "...                          ...\n",
       "46883    chr21_42801693_42801702\n",
       "46884  chr14_102154568_102154577\n",
       "46885   chr4_155339892_155339901\n",
       "46886   chr1_220612585_220612594\n",
       "46887    chr12_93470276_93470285\n",
       "\n",
       "[46888 rows x 1 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(motifs_list, columns=['motif']).to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [46], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[39mfor\u001b[39;00m i, filename \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(motifs_list):\n\u001b[1;32m      7\u001b[0m         \u001b[39m#print(filename)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         \u001b[39mwith\u001b[39;00m h5py\u001b[39m.\u001b[39mFile(h5files[i]) \u001b[39mas\u001b[39;00m f_src:\n\u001b[0;32m----> 9\u001b[0m             dset[i] \u001b[39m=\u001b[39m f_src[filename]\n\u001b[1;32m     11\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(motifs_list, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmotif\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mh5_db\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mdataset\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mdata_date\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl-tools/lib/python3.10/site-packages/h5py/_hl/dataset.py:902\u001b[0m, in \u001b[0;36mDataset.__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    899\u001b[0m     \u001b[39m# If the input data is already an array, let HDF5 do the conversion.\u001b[39;00m\n\u001b[1;32m    900\u001b[0m     \u001b[39m# If it's a list or similar, don't make numpy guess a dtype for it.\u001b[39;00m\n\u001b[1;32m    901\u001b[0m     dt \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(val, numpy\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase\n\u001b[0;32m--> 902\u001b[0m     val \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(val, order\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m'\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdt)\n\u001b[1;32m    904\u001b[0m \u001b[39m# Check for array dtype compatibility and convert\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39msubdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl-tools/lib/python3.10/site-packages/h5py/_hl/dataset.py:1046\u001b[0m, in \u001b[0;36mDataset.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m numpy\u001b[39m.\u001b[39mproduct(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnumpy\u001b[39m.\u001b[39mulonglong) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1044\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\n\u001b[0;32m-> 1046\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_direct(arr)\n\u001b[1;32m   1047\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/miniconda3/envs/dl-tools/lib/python3.10/site-packages/h5py/_hl/dataset.py:1007\u001b[0m, in \u001b[0;36mDataset.read_direct\u001b[0;34m(self, dest, source_sel, dest_sel)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     dest_sel \u001b[39m=\u001b[39m sel\u001b[39m.\u001b[39mselect(dest\u001b[39m.\u001b[39mshape, dest_sel)\n\u001b[1;32m   1006\u001b[0m \u001b[39mfor\u001b[39;00m mspace \u001b[39min\u001b[39;00m dest_sel\u001b[39m.\u001b[39mbroadcast(source_sel\u001b[39m.\u001b[39marray_shape):\n\u001b[0;32m-> 1007\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mid\u001b[39m.\u001b[39;49mread(mspace, fspace, dest, dxpl\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dxpl)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with h5py.File(f\"{h5_db}/{dataset}_{data_date}.hdf5\", \"w\") as f_dst:\n",
    "    #h5files = [f for f in os.listdir(f'{project_dir}/') if f.endswith(\".h5\")]\n",
    "\n",
    "    dset = f_dst.create_dataset(f'{dataset}_dataset', shape=(len(h5files), 17, 5313), dtype='f4')\n",
    "\n",
    "    for i, filename in enumerate(motifs_list):\n",
    "        #print(filename)\n",
    "        with h5py.File(h5files[i]) as f_src:\n",
    "            dset[i] = f_src[filename]\n",
    "\n",
    "pd.DataFrame(motifs_list, columns=['motif']).to_csv(f\"{h5_db}/{dataset}_{data_date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_predictions = {}\n",
    "\n",
    "with h5py.File(f\"{h5_db}/{dataset}_{data_date}.hdf5\", \"r\") as f_dst:\n",
    "    #h5files = [f for f in os.listdir(f'{project_dir}/') if f.endswith(\".h5\")]\n",
    "    output_predictions = f_dst.get(f'{dataset}_dataset')[()] \n",
    "    motifs = list(f_dst.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46887, 17, 5313)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mydataset']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Currently on freedman\n"
     ]
    }
   ],
   "source": [
    "print(f'[INFO] Currently on {dataset_type}')\n",
    "\n",
    "save_dir = f'{base_path}/aggregated_predictions/{dataset_type}_{TF}_{todays_date}'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "if individuals is None:\n",
    "    ids_names = [dataset_type]\n",
    "elif isinstance(individuals, list):\n",
    "    ids_names = individuals\n",
    "\n",
    "log_data_all = pd.read_csv(log_file)\n",
    "\n",
    "# use parsl if the num of rows of log_data is more than 10000\n",
    "use_parsl = False\n",
    "\n",
    "predict_utils_one = f'{script_path}/utilities/utility_functions.py'\n",
    "exec(open(predict_utils_one).read(), globals(), globals())\n",
    "\n",
    "if use_parsl == True:\n",
    "    #bpath = os.path.join(base_path, 'modeling_pipeline')\n",
    "    print(f'[INFO] Using parsl. Aggregation will be split into multiple files, and batches will be collected into one later.')\n",
    "    parsl_params = {'working_dir':base_path, 'job_name':'aggregate_predictions', 'queue':\"preemptable\", 'walltime':\"05:59:00\", 'num_of_full_nodes':1, 'min_num_blocks':0, 'max_num_blocks':10}\n",
    "    parsl.load(parslConfiguration.localParslConfig_htpool(parsl_params))\n",
    "\n",
    "collection_fxn = return_prediction_function(use_parsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motif</th>\n",
       "      <th>individual</th>\n",
       "      <th>status</th>\n",
       "      <th>sequence_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr12_92688598_92688607</td>\n",
       "      <td>LuCaP_136</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hr9_122819978_122819987</td>\n",
       "      <td>LuCaP_136</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr9_18363310_18363319</td>\n",
       "      <td>LuCaP_136</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr5_160240472_160240481</td>\n",
       "      <td>LuCaP_136</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr20_11244716_11244725</td>\n",
       "      <td>LuCaP_136</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9099</th>\n",
       "      <td>chrX_68854754_68854763</td>\n",
       "      <td>LuCaP_141</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9100</th>\n",
       "      <td>chr9_122819978_122819987</td>\n",
       "      <td>LuCaP_141</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9101</th>\n",
       "      <td>chr7_3576376_3576385</td>\n",
       "      <td>LuCaP_141</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9174</th>\n",
       "      <td>chr1_176593308_176593317</td>\n",
       "      <td>LuCaP_141</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9181</th>\n",
       "      <td>chr5_153476501_153476510</td>\n",
       "      <td>LuCaP_141</td>\n",
       "      <td>completed</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9103 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         motif individual     status sequence_type\n",
       "0      chr12_92688598_92688607  LuCaP_136  completed           var\n",
       "1      hr9_122819978_122819987  LuCaP_136  completed           var\n",
       "2       chr9_18363310_18363319  LuCaP_136  completed           var\n",
       "3     chr5_160240472_160240481  LuCaP_136  completed           var\n",
       "4      chr20_11244716_11244725  LuCaP_136  completed           var\n",
       "...                        ...        ...        ...           ...\n",
       "9099    chrX_68854754_68854763  LuCaP_141  completed           var\n",
       "9100  chr9_122819978_122819987  LuCaP_141  completed           var\n",
       "9101      chr7_3576376_3576385  LuCaP_141  completed           var\n",
       "9174  chr1_176593308_176593317  LuCaP_141  completed           var\n",
       "9181  chr5_153476501_153476510  LuCaP_141  completed           var\n",
       "\n",
       "[9103 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data_all = pd.read_csv(log_file)\n",
    "log_data_all.drop_duplicates(subset=['motif'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9103, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          motif individual     status sequence_type\n",
      "9098    chr12_92688598_92688607  LuCaP_141  completed           var\n",
      "9099     chrX_68854754_68854763  LuCaP_141  completed           var\n",
      "9100   chr9_122819978_122819987  LuCaP_141  completed           var\n",
      "9101       chr7_3576376_3576385  LuCaP_141  completed           var\n",
      "9102     chr3_24951897_24951906  LuCaP_141  completed           var\n",
      "...                         ...        ...        ...           ...\n",
      "18195   chr12_23533600_23533609  LuCaP_141  completed           var\n",
      "18196  chr5_102611585_102611594  LuCaP_141  completed           var\n",
      "18197    chr8_84108965_84108974  LuCaP_141  completed           var\n",
      "18198   chr21_24828757_24828766  LuCaP_141  completed           var\n",
      "18199    chr4_79041264_79041273  LuCaP_141  completed           var\n",
      "\n",
      "[9102 rows x 4 columns]\n",
      "(9102, 4)\n",
      "[range(1138, 2276), range(2276, 3414), range(3414, 4552), range(4552, 5690), range(5690, 6828), range(6828, 7966), range(7966, 9102)]\n",
      "['0: 1138']\n"
     ]
    }
   ],
   "source": [
    "ids_names = ['LuCaP_141']\n",
    "\n",
    "for each_id in ids_names:\n",
    "    log_data = log_data_all.loc[log_data_all['individual'] == each_id, ]\n",
    "    log_data = log_data.drop_duplicates(subset=['motif']) #.iloc[1:1000, ]\n",
    "\n",
    "    print(log_data)\n",
    "\n",
    "    print(log_data.shape)\n",
    "\n",
    "    range_batches = generate_batch(range(0, log_data.shape[0]), batch_n=8)\n",
    "\n",
    "    ind_path = os.path.join(enformer_predictions_path, each_id)\n",
    "\n",
    "    app_futures = []\n",
    "    for i, range_batch in enumerate(range_batches):\n",
    "\n",
    "        print(list(range_batches))\n",
    "        app_futures.append(f'{i}: {len(range_batch)}')\n",
    "\n",
    "        # print(i)\n",
    "        # app_futures.append(collection_fxn(each_id=each_id, log_data=log_data.iloc[range_batch, ], predictions_path=ind_path, TF=TF, agg_types=[agg_type], base_path=base_path, save_dir=save_dir, batch_num=i))\n",
    "\n",
    "    print(app_futures)\n",
    "\n",
    "    if use_parsl == True:\n",
    "        app_execs = [r.result() for r in app_futures]\n",
    "\n",
    "    # cmd = f\"for i in `ls {save_dir}/{each_id}_{agg_type}_{TF}_batch_*.csv.gz`; do zcat $i | sed '1d'; done | pigz -c >{save_dir}/{each_id}_{agg_type}_{TF}.csv.gz\"    \n",
    "    # p = subprocess.Popen(cmd, shell=True)\n",
    "    # print(f'[INFO] Status: Aggregation complete for {log_data.shape[0]} predictions for {each_id}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6dcac1a71ccad94eb769456e80f90aa894f3068a5275ffeae8fac07a2d93c97a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
