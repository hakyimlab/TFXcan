






### Remove all TF chip seq

```{r}
tf_chipseq_feature_names <- enformer_annotations$feature_names[enformer_annotations$assay == 'TF ChIP-seq']
```

```{r}
# register a parallel backend 
registerDoMC(cores = 4)
```

```{r}
X_train_without_TF_chip <- X_train[, !colnames(X_train) %in% tf_chipseq_feature_names]
X_test_without_TF_chip <- X_test[, !colnames(X_test) %in% tf_chipseq_feature_names]
```

```{r}
# fitting the models; uses elastic net mixing parameter of 0.5
enet_fit_aggByMean_no_TF_chip <- cv.glmnet(x=X_train_without_TF_chip[complete.cases(X_train_without_TF_chip),], y=y_train[complete.cases(X_train_without_TF_chip)], family = "binomial", 
type.measure = "auc", alpha = 0.5, parallel=T, keep=T)
```

```{r}
enet_fit_aggByMean_no_TF_chip |> plot()
mtext('AUC across lambdas; aggByMean; All tracks except GATA3\'s', side=3, line=3, cex=1.5)
```


```{r}
min_error_index <- enet_fit_aggByMean_no_TF_chip$index['min', ]
one_sd_index <- enet_fit_aggByMean_no_TF_chip$index['1se', ]
# ENet_fit$glmnet.fit$beta
```

```{r}
dimensions <- enet_fit_aggByMean_no_TF_chip$glmnet.fit$beta@Dim
coef_mat <- as.data.frame(summary(enet_fit_aggByMean_no_TF_chip$glmnet.fit$beta))
cat(colnames(coef_mat))

temp_mat <- matrix(data=NA, nrow=dimensions[1], ncol=dimensions[2])
for(i in 1:nrow(coef_mat)){
    temp_mat[coef_mat[i, 'i'], coef_mat[i, 'j']] <- coef_mat[i, 'x']
}

temp_mat[is.na(temp_mat)] <- 0
```

```{r}
df_beta <- cbind(temp_mat[, min_error_index], temp_mat[, one_sd_index])
df_beta_labels <- c('For lambda with minimum mean cv error', 'For largest lambda with 1 s.e within the mininum error')

# what features were used?
feature_data <- enformer_annotations[enformer_annotations$feature_names %in% colnames(X_train_without_TF_chip), c('assay', 'feature_names')]

df_beta <- as.data.frame(cbind(df_beta, feature_data))
```

How many of those features had non-zero coefficients by group?

```{r}
num_features <- cbind(V1=df_beta[df_beta$V1 != 0, ]$assay |> table(), V2=df_beta[df_beta$V2 != 0, ]$assay |> table())
num_features
```

How many non-zero coefficients between both?
```{r}
df_beta[(df_beta$V1 != 0) & (df_beta$V2 != 0), ]$assay |> table()
```

```{r}
useColors <- RColorBrewer::brewer.pal(n=8, name='Dark2')
```

```{r}
df_beta_split <- split(df_beta, df_beta$assay)

# define the layout
layout(matrix(c(1,3,2,3), nrow = 2, ncol = 2, byrow = T), height=c(5, 5), width=c(8,1.3))
par(mar=c(0.5,2.5,2,2) + 0.1, oma=c(3.5, 2.0, 3.5, 0.5) + 0.1)

for(i in 1:2){

    ylimits <- c(min(df_beta[, i]), max(df_beta[, i]))
    #print(ylimits)

    plot(x=df_beta_split[[1]] |> row.names() |> as.numeric(), y=df_beta_split[[1]][, i], type='l', col=useColors[1], xlim=c(1, nrow(df_beta)), ylim=ylimits, xaxt='n', main=df_beta_labels[i])

    for(j in 2:length(df_beta_split)){
        lines(x=df_beta_split[[j]] |> row.names() |> as.numeric(), y=df_beta_split[[j]][, i], col=useColors[j])
    }
    #mtext('TTTT', side=1, outer=T, cex=1.2)
}

axis(1, at=seq(1, nrow(df_beta)))
mtext('tracks', side=1, outer=T, cex=1.2, line=2)
mtext('coefficients', side=2, outer=T, cex=1.2)
mtext('Distribution of coefficients across tracks; aggByMean; No TF Chip', side=3, outer=T, cex=1.3, adj=0)

par(mai=c(0,0,0,0))
plot.new()
legend('right', legend=names(df_beta_split), col=useColors[1:length(df_beta_split)], lty=1, bty='n')

```

\newpage
### Remove all TF chip seq and CAGE tracks

```{r}
use_feature_names <- enformer_annotations$feature_names[enformer_annotations$assay == 'TF ChIP-seq' | enformer_annotations$assay == 'CAGE experiment']
```

```{r}
# register a parallel backend 
registerDoMC(cores = 4)
```

```{r}
X_train_use <- X_train[, !colnames(X_train) %in% use_feature_names]
X_test_use <- X_test[, !colnames(X_test) %in% use_feature_names]
```

```{r}
# fitting the models; uses elastic net mixing parameter of 0.5
enet_fit_aggByMean_no_TF_CAGE <- cv.glmnet(x=X_train_use[complete.cases(X_train_use),], y=y_train[complete.cases(X_train_use)], family = "binomial", 
type.measure = "auc", alpha = 0.5, parallel=T, keep=T)
```

```{r}
enet_fit_aggByMean_no_TF_CAGE |> plot()
mtext('AUC across lambdas; aggByMean; No TF or CAGE', side=3, line=3, cex=1.5)
```

```{r}
min_error_index <- enet_fit_aggByMean_no_TF_CAGE$index['min', ]
one_sd_index <- enet_fit_aggByMean_no_TF_CAGE$index['1se', ]
# ENet_fit$glmnet.fit$beta
```

```{r}
dimensions <- enet_fit_aggByMean_no_TF_CAGE$glmnet.fit$beta@Dim
coef_mat <- as.data.frame(summary(enet_fit_aggByMean_no_TF_CAGE$glmnet.fit$beta))
cat(colnames(coef_mat))

temp_mat <- matrix(data=NA, nrow=dimensions[1], ncol=dimensions[2])
for(i in 1:nrow(coef_mat)){
    temp_mat[coef_mat[i, 'i'], coef_mat[i, 'j']] <- coef_mat[i, 'x']
}

temp_mat[is.na(temp_mat)] <- 0
```

```{r}
df_beta <- cbind(temp_mat[, min_error_index], temp_mat[, one_sd_index])
df_beta_labels <- c('For lambda with minimum mean cv error', 'For largest lambda with 1 s.e within the mininum error')

# what features were used?
feature_data <- enformer_annotations[enformer_annotations$feature_names %in% colnames(X_train_use), c('assay', 'feature_names')]

df_beta <- as.data.frame(cbind(df_beta, feature_data))
```

How many of those features had non-zero coefficients by group?

```{r}
num_features <- cbind(V1=df_beta[df_beta$V1 != 0, ]$assay |> table(), V2=df_beta[df_beta$V2 != 0, ]$assay |> table())
num_features
```

How many non-zero coefficients between both?
```{r}
df_beta[(df_beta$V1 != 0) & (df_beta$V2 != 0), ]$assay |> table()
```

```{r}
useColors <- RColorBrewer::brewer.pal(n=8, name='Dark2')
```

```{r}
df_beta_split <- split(df_beta, df_beta$assay)

# define the layout
layout(matrix(c(1,3,2,3), nrow = 2, ncol = 2, byrow = T), height=c(5, 5), width=c(8,1.3))
par(mar=c(0.5,2.5,2,2) + 0.1, oma=c(3.5, 2.0, 3.5, 0.5) + 0.1)

for(i in 1:2){

    ylimits <- c(min(df_beta[, i]), max(df_beta[, i]))
    #print(ylimits)

    plot(x=df_beta_split[[1]] |> row.names() |> as.numeric(), y=df_beta_split[[1]][, i], type='l', col=useColors[1], xlim=c(1, nrow(df_beta)), ylim=ylimits, xaxt='n', main=df_beta_labels[i])

    for(j in 2:length(df_beta_split)){
        lines(x=df_beta_split[[j]] |> row.names() |> as.numeric(), y=df_beta_split[[j]][, i], col=useColors[j])
    }
    #mtext('TTTT', side=1, outer=T, cex=1.2)
}

axis(1, at=seq(1, nrow(df_beta)))
mtext('tracks', side=1, outer=T, cex=1.2, line=2)
mtext('coefficients', side=2, outer=T, cex=1.2)
mtext('Distribution of coefficients across tracks; aggByMean; No TF or CAGE', side=3, outer=T, cex=1.3, adj=0)

par(mai=c(0,0,0,0))
plot.new()
legend('right', legend=names(df_beta_split), col=useColors[1:length(df_beta_split)], lty=1, bty='n')
```








Performance on the test set ===

Prediction/AUC on the training 
glmnet has an in-built function for this but I prefer to use ROCR's
```{r}
train_predictions <- predict(enet_fit_aggByMean, newx=X_train, type='response')
test_predictions <- predict(enet_fit_aggByMean, newx=X_test, type='response')

train_pred <- ROCR::prediction(train_predictions, y_train)
test_pred <- ROCR::prediction(test_predictions, y_test)

train_perf <- ROCR::performance(train_pred, "tpr", "fpr")
test_perf <- ROCR::performance(test_pred, "tpr", "fpr")

train_perf_pr <- ROCR::performance(train_pred, "prec", "rec")
test_perf_pr <- ROCR::performance(test_pred, "prec", "rec")
```

```{r}
plt_perf <- c(train_perf, test_perf, train_perf_pr, test_perf_pr)
names_plt_perf <- c('training roc', 'test roc','training PR', 'test PR')
```

`pred` is a prediction instance - can assess with `@`

```{r}

layout(matrix(c(1:4), nrow = 2, ncol = 2, byrow = T), heights = c(4.0, 4.0))
# par(mar=rep(0.01, 4))
# plot.new()
# legend('center', legend=c('theoretical', 'regression'), col=c('black', 'red'), lty=1)
#par(mfrow=c(2,2), oma = c(3.5,3.5,1,1) + 0.1, mar = c(3,1.5,1,1) + 0.1,)
par(mar=c(2.5,2.5,2,2) + 0.1, oma=c(3.0, 3.0, 0.5, 0.5) + 0.1)

#performance(pred,"auc") # shows calculated AUC for model

for(i in 1:length(plt_perf)){

    plot(plt_perf[[i]], colorize = F, col="black", main=names_plt_perf[[i]], frame.plot=F) # plot ROC curve
    if(i %in% c(1:2)){
        lines(c(0,1),c(0,1),col = "gray", lty = 4)
        mtext('Hello', 4, 3, outer=T) 
    }
}

```

```{r}
assess.glmnet(enet_fit_aggByMean, newx = X_test, newy = y_test) |> unlist()
```

Looks like the precision-recall curve is not so good. 

Here, I check the distribution of the coefficients
```{r}
hist(coef(enet_fit_aggByMean) |> as.numeric(), main='Distribution of coefficients', xlab='coefficients')
```


What track gives the largest coefficient?
```{r}
df_beta[which.max(df_beta$value[df_beta$name=='V1']), ]
df_beta[which.max(df_beta$value[df_beta$name=='V2']), ]
```


\newpage
# Using the motif bin

```{r}
ind <- 'HG00479'
```

```{r}
train_data <- read.csv(glue('/projects/covid-ct/imlab/users/temi/projects/TFXcan/output/train-test-data/train_aggByCenter_{ind}.csv'))

X_train <- as.matrix(train_data[, -c(1)])
y_train <- as.matrix(train_data[, 1])

test_data <- read.csv(glue('/projects/covid-ct/imlab/users/temi/projects/TFXcan/output/train-test-data/test_aggByCenter_{ind}.csv'))

X_test <- as.matrix(test_data[, -c(1)])
y_test <- as.matrix(test_data[, 1])
```

```{r}
# register a parallel backend 
registerDoMC(cores = 4)
```
```{r}
enet_fit_aggByCenter <- cv.glmnet(x=X_train[complete.cases(X_train),], y=y_train[complete.cases(X_train)], family = "binomial", 
type.measure = "auc", alpha = 0.5, parallel=T, keep=T)
```

```{r}
par(oma=c(1.0, 1.0, 3, 0.5) + 0.1)
enet_fit_aggByCenter |> plot()
mtext('AUC across lambdas; aggByCenter; minus all GATA3 tracks', side=3, line=3, cex=1.5)

# dev.copy(png, glue('{plots_dir}/except-GATA3-aggByMean.png'))
# dev.off()
```

```{r}
min_error_index <- enet_fit_aggByCenter$index['min', ]
one_sd_index <- enet_fit_aggByCenter$index['1se', ]
# ENet_fit$glmnet.fit$beta
```

```{r}
dimensions <- enet_fit_aggByCenter$glmnet.fit$beta@Dim
coef_mat <- as.data.frame(summary(enet_fit_aggByCenter$glmnet.fit$beta))
cat(colnames(coef_mat))

temp_mat <- matrix(data=NA, nrow=dimensions[1], ncol=dimensions[2])
for(i in 1:nrow(coef_mat)){
    temp_mat[coef_mat[i, 'i'], coef_mat[i, 'j']] <- coef_mat[i, 'x']
}

temp_mat[is.na(temp_mat)] <- 0
```

```{r}
df_beta <- cbind(temp_mat[, min_error_index], temp_mat[, one_sd_index])
df_beta_labels <- c('For lambda with minimum mean cv error', 'For largest lambda with 1 s.e within the mininum error')
```

```{r}
#png(glue('{plots_dir}/spread-of-coefficients-except-GATA3-aggByCenter.png'))

layout(matrix(c(1:2), nrow = 2, ncol = 1, byrow = T))
# par(mar=rep(0.01, 4))
# plot.new()
# legend('center', legend=c('theoretical', 'regression'), col=c('black', 'red'), lty=1)
#par(mfrow=c(2,2), oma = c(3.5,3.5,1,1) + 0.1, mar = c(3,1.5,1,1) + 0.1,)
par(mar=c(2.5,2.5,2,2) + 0.1, oma=c(1.0, 1.0, 3.5, 0.5) + 0.1)

for(i in 1:2){
    plot(df_beta[, i], type='b', xlab='bins', xaxt='n', ylab='coefficients', main=df_beta_labels[i])
    axis(1, at=seq(1, 5310))
    #abline(v=motif_center, col='red')
    mtext('tracks', side=1, outer=T, cex=1.2)
    mtext('coefficients', side=2, outer=T, cex=1.2)
}

mtext('Distribution of coefficients across tracks; aggByCenter; minus all GATA3 tracks', side=3, outer=T, cex=1.3)

# dev.copy(png, glue('{plots_dir}/spread-of-coefficients.png'))
# dev.off()

```

```{r}
#dev.print(png, glue('{plots_dir}/spread-of-coefficients-except-GATA3-aggByCenter.png'), width=3)
#dev.off()
```