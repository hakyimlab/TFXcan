---
title: "Exploring Baca's CWAS models + creating DBs"
author: "Temi"
description: "..."
date: 'Tues Aug 8 2023'
html:
    self-contained: true
    code-background: true
fig-format: svg
---

# Introduction

Here, I explore Baca's CWAS models, and create necessary DBs suitable in a Predixcan framework

```{r}
library(data.table)
library(glue)
library(dplyr)
```

```{r}
tdate <- '2023-08-17'

base_dir <- '/project2/haky/temi/projects/TFXcan/baca_cwas'
data_dir <- '/project2/haky/Data/baca_cwas/cwas_weights'
#project_dir <- '/lus/grand/projects/TFXcan/imlab/users/temi/projects/TFXcan/baca_cwas'
output_dir <- glue('{base_dir}/data')
files_dir <- glue('{base_dir}/files')
if(!(dir.exists(files_dir))){
    dir.create(files_dir, recursive = T)
}
transcription_factor <- 'AR'

bedmappings <- glue('{base_dir}/mappings/baca_cwas_loci_hg38.bed')
snpmappings <- glue('{base_dir}/mappings/hg38_snps.bed')
```


```{r}
ar_zip <- glue('{data_dir}/AR.zip')
print(file.exists(ar_zip))
```

First unzip the file
```{r}

if(!dir.exists(glue('{output_dir}/{transcription_factor}'))){
    file_names <- unzip(ar_zip, list=T)$Name
    files_to_read <- grep(pattern='^\\bAR\\b.*\\bRDat\\b$', x=file_names, value=T)
    files_to_read[1:5]

    # unzip the file
    zip::unzip(ar_zip, files=files_to_read, exdir=output_dir)
    

} 

ar_files <- list.files(glue('{output_dir}/{transcription_factor}'))
ar_files_locus <- sapply(strsplit(x=ar_files, split='\\.'), getElement, 1)
ar_files_locus[1:5]

```

```{r}
rdt <- new.env(parent = emptyenv())
load(file.path(output_dir, transcription_factor, ar_files[1]), envir=rdt)
```

Next, read the files `.wgt` files
```{r}
# /project2/haky/temi/projects/TFXcan/baca_cwas
out <- purrr::map(.x=seq_along(ar_files_locus), .f=function(i){
    locus <- ar_files_locus[i]
    #print(file.exists(glue('{output_dir}/{transcription_factor}/{locus}.wgt.RDat')))
    rdt <- new.env(parent = emptyenv())
    load(glue('{output_dir}/{transcription_factor}/{locus}.wgt.RDat'), envir=rdt)
    wgts <- as.data.frame(rdt$wgt.matrix) %>% 
        tibble::rownames_to_column('snp_id') %>% 
        dplyr::mutate(locus=locus)
    
    snp_info <- rdt$snps %>% 
        as.data.frame() %>% 
        dplyr::select(all_of(c('V1', 'V3', 'V2', 'V4', 'V5'))) 

    colnames(snp_info) <- c('chr', 'snp_id', 'position', 'a1', 'a2')

    dt <- base::merge(wgts, snp_info, by='snp_id') %>% 
        dplyr::relocate(all_of(c('locus', 'chr', 'position', 'a1', 'a2')), .after=snp_id)
    return(dt)
}, .progress=T)

cwas_db <- do.call('rbind', out)

dim(cwas_db) ; cwas_db[1:5, ]
```

```{r}
# collect extra columns
extra_dt <- purrr::map(.x=1:length(ar_files_locus), .f=function(i){
    locus <- ar_files_locus[i]
    rdt <- new.env(parent = emptyenv())
    load(glue('{output_dir}/{transcription_factor}/{locus}.wgt.RDat'), envir=rdt)
    extra <- c(locus, transcription_factor, rdt$N.tot, rdt$N.as, rdt$cv.performance[c('rsq', 'pval'), c('lasso')] |> unname()) |> as.data.frame() |> t() |> unname()
    return(extra)
}, .progress=T)

extra_dt <- do.call('rbind', extra_dt) |> as.data.frame()
colnames(extra_dt) <- c('locus', 'transcription_factor', 'n_snps_in_window', "n.snps.in.model", "pred.perf.R2", "pred.perf.pval")
extra_dt[1:5, ]
```

```{r}
data.table::fwrite(cwas_db, file=glue('{files_dir}/{transcription_factor}_baca_cwas_weights_{tdate}.txt.gz'), row.names=F, quote=F, compress='gzip', sep='\t')

data.table::fwrite(extra_dt, file=glue('{files_dir}/{transcription_factor}_baca_cwas_extras_{tdate}.txt.gz'), row.names=F, quote=F, compress='gzip', sep='\t')
```

if you have a lifted over bed file, you can continue
Read in new bed files and match 
```{r}
hg38_bed_files <- data.table::fread(bedmappings, col.names=c('chr', 'hg38_start', 'hg38_end', 'hg19_id'))
hg38_bed_files <- hg38_bed_files %>% 
    dplyr::mutate(hg38_id=paste(paste(chr, hg38_start, sep=':'), hg38_end, sep='-')) %>%
    dplyr::select(chr, hg19_id, hg38_id)
hg38_bed_files$chr <- as.numeric(gsub(pattern='chr', replacement='', x=hg38_bed_files$chr))
hg38_bed_files[1:5, ]
```

```{r}
hg38_cwas_db <- dplyr::left_join(cwas_db, hg38_bed_files, by=c('locus' = 'hg19_id', 'chr'='chr'))
hg38_cwas_db$locus <- hg38_cwas_db$hg38_id
hg38_cwas_db$hg38_id <- NULL
hg38_cwas_db[1:5, ] ; dim(hg38_cwas_db)
```

Match the `extras` too

```{r}
hg38_cwas_extra <- dplyr::left_join(extra_dt, hg38_bed_files, by=c('locus' = 'hg19_id'))
hg38_cwas_extra$locus <- hg38_cwas_extra$hg38_id
hg38_cwas_extra$hg38_id <- NULL
hg38_cwas_extra[1:5, ] ; dim(hg38_cwas_extra)
```

Merge with the hg38 snps
```{r}
hg38_snp_files <- data.table::fread(snpmappings, col.names=c('chr', 'hg38_start', 'hg38_end', 'snp_id', 'hg38_locus'))
hg38_snp_files$chr <- as.numeric(gsub(pattern='chr', replacement='', x=hg38_snp_files$chr))
hg38_snp_files[1:5, ]
```

```{r}
tt <- dplyr::left_join(hg38_cwas_db, hg38_snp_files, by=c('locus' = 'hg38_locus', 'snp_id'='snp_id', 'chr' = 'chr'))
tt$position <- tt$hg38_start
tt$hg38_start <- tt$hg38_end <- NULL
tt[1:5, ] ; dim(tt)
```

```{r}
# write out the snps to a file
data.table::fwrite(tt, file=glue('{files_dir}/{transcription_factor}_baca_cwas_weights_hg38_{tdate}.txt.gz'), col.names=T, row.names=F, quote=F, compress='gzip',sep = '\t')

data.table::fwrite(hg38_cwas_extra, file=glue('{files_dir}/{transcription_factor}_baca_cwas_extra_hg38_{tdate}.txt.gz'), col.names=T, row.names=F, quote=F, compress='gzip',sep = '\t')
```


## Create databases


Here I will write out two folders: one with `1...` and `chr1...`
```{r}
library(RSQLite)
library(dbplyr)
library(DBI)
```

```{r}
db_folder <- glue('{base_dir}/db_folder')
if(!dir.exists(db_folder)){dir.create(db_folder)}

db_folder_chr <- glue('{base_dir}/db_folder_chr')
if(!dir.exists(db_folder_chr)){dir.create(db_folder_chr)}
```


```{r}
# write out the snps to a file
baca_weights <- data.table::fread(glue('{files_dir}/{transcription_factor}_baca_cwas_weights_hg38_{tdate}.txt.gz'))
baca_weights$varIDs <- with(baca_weights, paste0(chr, '_', position, '_', a1, '_', a2, '_', 'b38', sep=''))
baca_weights$chr_varIDs <- with(baca_weights, paste0('chr', chr, '_', position, '_', a1, '_', a2, '_', 'b38', sep=''))
baca_weights[1:5, ]
```

Baca has 6 models/weights

```{r}
baca_models <- c('lasso', 'lasso.as', 'lasso.plasma', 'top1.as', 'top1.qtl', 'top1')
```

```{r}
baca_extra <- data.table::fread(glue('{files_dir}/{transcription_factor}_baca_cwas_extra_hg38_{tdate}.txt.gz'))
baca_extra <- baca_extra %>% dplyr::rename(gene=locus, genename=transcription_factor)
baca_extra$pred.perf.qval <- NA
baca_extra[1:5, ]
```

Predict_db format

```{r}
baca_weights_list <- purrr::map(.x=baca_models, function(each_m){
    model_weights <- baca_weights %>% 
        dplyr::select(gene=locus, rsid=snp_id, varID=varIDs, ref_allele=a1, eff_allele=a2, weight=as.symbol(each_m)) %>% as.data.frame()

    each_db <- DBI::dbConnect(RSQLite::SQLite(), glue('{db_folder}/baca_cwas_{each_m}.db'))
    dbWriteTable(each_db, "extra", baca_extra, overwrite=T)
    dbWriteTable(each_db, "weights", model_weights, overwrite=T)
    dbDisconnect(each_db)

    model_weights <- baca_weights %>% 
        dplyr::select(gene=locus, rsid=snp_id, varID=chr_varIDs, ref_allele=a1, eff_allele=a2, weight=as.symbol(each_m)) %>% as.data.frame()

    each_db <- DBI::dbConnect(RSQLite::SQLite(), glue('{db_folder_chr}/baca_cwas_{each_m}.db'))
    dbWriteTable(each_db, "extra", baca_extra, overwrite=T)
    dbWriteTable(each_db, "weights", model_weights, overwrite=T)
    dbDisconnect(each_db)

    return(0)
})

names(baca_weights_list) <- baca_models
```




Now you can look at one of them...
```{r}
lasso_db <- DBI::dbConnect(RSQLite::SQLite(), glue('{db_folder}/baca_cwas_lasso.db'))
extra_dt <- tbl(lasso_db, 'extra') %>% as.data.frame()
weights_dt <- tbl(lasso_db, 'weights') %>% as.data.frame()

dbDisconnect(lasso_db)
```

```{r}
extra_dt |> head() ; weights_dt |> head()
```



```{r}
lasso_db <- DBI::dbConnect(RSQLite::SQLite(), glue('{db_folder_chr}/baca_cwas_lasso.db'))
extra_dt <- tbl(lasso_db, 'extra') %>% as.data.frame()
weights_dt <- tbl(lasso_db, 'weights') %>% as.data.frame()

dbDisconnect(lasso_db)
```

```{r}
extra_dt |> head() ; weights_dt |> head()
```